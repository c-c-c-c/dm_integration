{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myMecab",
      "provenance": [],
      "collapsed_sections": [
        "0zHt5kiTa-9d",
        "fUP0dONFa-9y",
        "e9T8K1Sba-97",
        "ghxLSFzAa-98",
        "PiWBOEJ6a--J",
        "-rYChGyna--O",
        "JIAl91qja--Q",
        "S88NkqlQa--Z",
        "zgstWu1sa--j",
        "G5fYOekxa--n",
        "CB2NQkE2a--w"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-c-c-c/dm_integration/blob/master/myMecab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R8Oh-JGka-8_"
      },
      "source": [
        "# テキストの分類\n",
        "テキスト分類は、以下の順に行います。\n",
        "\n",
        "1. 前処理\n",
        "2. 数値表現化 (CountVectorizer, TfIdfVectorizer)\n",
        "3. 分類器を学習\n",
        "\n",
        "本ノートブックでは、Wikipedia のエントリ分類を通じて、テキスト分類器を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qkpjTGlYJdq",
        "colab_type": "code",
        "outputId": "44fb7f9e-733f-400d-d860-876e529b1331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P-6WpdMM7ywT",
        "outputId": "fbd870ad-c5ba-440d-9e05-79f3b817bcde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
            "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
            "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "Suggested packages:\n",
            "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
            "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
            "  libwww-perl xapian-tools\n",
            "The following NEW packages will be installed:\n",
            "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
            "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
            "  libhttp-message-perl libio-html-perl libio-string-perl\n",
            "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
            "  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "0 upgraded, 21 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 3,877 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
            "Fetched 3,877 kB in 1s (3,310 kB/s)\n",
            "Selecting previously unselected package aptitude-common.\n",
            "(Reading database ... 134443 files and directories currently installed.)\n",
            "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
            "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
            "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
            "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libcwidget3v5:amd64.\n",
            "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
            "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aptitude.\n",
            "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
            "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libclass-accessor-perl.\n",
            "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
            "Unpacking libclass-accessor-perl (0.51-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libio-string-perl.\n",
            "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
            "Unpacking libio-string-perl (1.08-3) ...\n",
            "Selecting previously unselected package libparse-debianchangelog-perl.\n",
            "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
            "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up libio-string-perl (1.08-3) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Setting up libclass-accessor-perl (0.51-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.5)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.8)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.5)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.8)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
            "The following packages will be REMOVED:\n",
            "  libnvidia-common-430{u} \n",
            "0 packages upgraded, 11 newly installed, 1 to remove and 25 not upgraded.\n",
            "Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n",
            "Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.3 [184 kB]\n",
            "Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.3 [68.7 kB]\n",
            "Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.3 [22.1 kB]\n",
            "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 29.3 MB in 2s (16.2 MB/s)\n",
            "(Reading database ... 134902 files and directories currently installed.)\n",
            "Removing libnvidia-common-430 (430.64-0ubuntu0~gpu18.04.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 134897 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.3) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPKMuQKTFTGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ahF2OfXfa-9B",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "import MeCab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DUHMMXZRa-9E"
      },
      "source": [
        "## データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YCwAqWLba-9F",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# EPGデータ(手作業での修正中))\n",
        "df = pd.read_excel(\"./drive/My Drive/0_インテグ作業/data/EPG_checking0212.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4G9yZISyV6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f= open(\"./drive/My Drive/0_インテグ作業/data/drama_category0214.json\", 'r')\n",
        "\n",
        "#ココ重要！！\n",
        "drama_category_dic = json.load(f) #JSON形式で読み込む\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9FqflXpeGw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f= open(\"./drive/My Drive/0_インテグ作業/data/drama_win_lose.json\", 'r')\n",
        "\n",
        "#ココ重要！！\n",
        "drama_win_lose_dic = json.load(f) #JSON形式で読み込む\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsgYtGJayVy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bcULFLByVi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Il7MOeFyTra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN9Ikeaa990W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-SFrbJDgbFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ゴミ除去\n",
        "\n",
        "def removeTrash (text):\n",
        "    import re\n",
        "\n",
        "    result_text = text\n",
        "    result_text = re.sub(r\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\", \"\", result_text)\n",
        "    result_text = re.sub(r\"番組詳細|制作・著作|制作著作\", \"\", result_text)\n",
        "    result_text = re.sub(r\"[!\\(\\)=『』～/]\", \"\", result_text)\n",
        "    result_text = re.sub(r\"フジテレビ|日本テレビ|TBS|テレビ朝日|TBS|関西テレビ\", \"\", result_text)\n",
        "    \n",
        "    result_text = re.sub(r\"【公式.*?】\", \"\", result_text)\n",
        "    result_text = re.sub(r\"\\u3000\", \"\", result_text)\n",
        "\n",
        "    return result_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIgBCGTUcorI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mecab = MeCab.Tagger()\n",
        "mecab.parse(\"\")\n",
        "for i, text in enumerate( df['sharp_epg_hand_corrected']):\n",
        "    text_tokenized = []\n",
        "    # print(i)\n",
        "\n",
        "    # URL、記号などのゴミを取り除く\n",
        "    if type(text) is not str: \n",
        "        if np.isnan(text) :\n",
        "            continue \n",
        "    text = removeTrash(text)\n",
        "    node = mecab.parseToNode(text)\n",
        "    while node:\n",
        "        node = node.next\n",
        "        if node is None:\n",
        "            continue\n",
        "\n",
        "        if not node.feature.startswith(\"BOS/EOS\") and not node.feature.startswith(\"助詞\") and\\\n",
        "            not node.feature.startswith(\"記号\") and\\\n",
        "            node.feature.find(\"人名\") == -1 and\\\n",
        "            not node.feature.startswith(\"助動詞\"):\n",
        "            text_tokenized.append(node.surface)\n",
        "\n",
        "    df[\"sharp_epg_tknz\"].iloc[i] = text_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkohrTp-ot6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 手作業での前処理が完了してないので、完了したものだけにする\n",
        "bool_list = [] \n",
        "\n",
        "for i in range(len(df[\"sharp_epg_hand_corrected\"])):\n",
        "    bool_list.append( type( df[\"sharp_epg_tknz\"].iloc[i] ) != float )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBaS8qJ3xOfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_notnull =  df[bool_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqLRG7vYDeob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_notnull[\"phys_cnt\"] = np.nan\n",
        "df_notnull[\"category\"] = np.nan\n",
        "df_notnull =  df_notnull.rename(columns={ 'Unnamed: 0' : 'sort_id' } )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X2mHTM_DwqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drama_category_dic.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdaTOtJhtd0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 物理カウントとカテゴリーを加える\n",
        "love_cnt = 0\n",
        "police_cnt = 0\n",
        "for tmp_key  in df_notnull[\"drama_key\"].unique():\n",
        "    cnt = 0\n",
        "\n",
        "    if tmp_key in drama_category_dic[\"love\"]:\n",
        "        print(\"love☆\")\n",
        "        love_cnt += 1\n",
        "\n",
        "        qry_l = \" drama_key == @tmp_key\"\n",
        "        target_idx = df_notnull.query(qry_l).index\n",
        "        df_notnull[ \"category\" ].loc [target_idx] = \"love\"\n",
        "\n",
        "\n",
        "    if tmp_key in drama_category_dic[\"plice\"]:\n",
        "        police_cnt += 1\n",
        "        qry_p = \" drama_key == @tmp_key\"\n",
        "        target_idx = df_notnull.query(qry_p).index\n",
        "        df_notnull[ \"category\" ].loc [target_idx] = \"police\"\n",
        "        # print(police_cnt)\n",
        "\n",
        "    for sort_id in  df_notnull[df_notnull[\"drama_key\"] == tmp_key]['sort_id'].values:\n",
        "        cnt  += 1\n",
        "\n",
        "        qry = \" sort_id == @sort_id\"\n",
        "        target_idx = df_notnull.query(qry).index\n",
        "        df_notnull[\"phys_cnt\"].loc[target_idx] = cnt\n",
        "\n",
        "    print(tmp_key)\n",
        "\n",
        "\n",
        "# df = pd.DataFrame( columns=['A','B'] )\n",
        "# 行を作る\n",
        "# tmp_se = pd.Series( [ i, i*i ], index=list_df.columns )\n",
        "# # dfに行をレコードとして追加\n",
        "# df = df.append( tmp_se, ignore_index=True )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ZAQxRQYkGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_notnull[df_notnull[\"category\"] == \"love\"].drama_key.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTaeB60Gb6_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tmp_key = \"1807_TBS_日21\"\n",
        "# qry = \"drama_key == @tmp_key & phys_cnt < 4 \"\n",
        "# str(df_notnull.query(qry)[\"sharp_epg_hand_corrected\"].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EHNze-lj2hE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHbp7_bmNr_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.DataFrame( columns=['A','B'] )\n",
        "# 行を作る\n",
        "# tmp_se = pd.Series( [ i, i*i ], index=list_df.columns )\n",
        "# # dfに行をレコードとして追加\n",
        "# df = df.append( tmp_se, ignore_index=True )\n",
        "\n",
        "\n",
        "df_stage = pd.DataFrame( columns=['drama_key','drama_title','stages','epg_joined','drama_category','win_lose'] )\n",
        "\n",
        "# df_notnull[\"drama_key\"].\n",
        "\n",
        "for tmp_key in df_notnull[df_notnull[\"category\"] == \"love\"].drama_key.unique():\n",
        "\n",
        "    win_or_lose = \"\"\n",
        "    if tmp_key in drama_win_lose_dic[\"win\"]:\n",
        "        win_or_lose = \"win\"\n",
        "    elif tmp_key in drama_win_lose_dic[\"draw\"]:\n",
        "        win_or_lose = \"draw\"\n",
        "    elif tmp_key in drama_win_lose_dic[\"lose\"]:\n",
        "        win_or_lose = \"lose\"\n",
        "    else:\n",
        "        print(\"????\")\n",
        "\n",
        "        target_idx = df_stage.query(qry_wl).index\n",
        "        df_notnull[ \"category\" ].loc [target_idx] = \"police\"\n",
        "        # print(police_cnt)\n",
        "\n",
        "\n",
        "    for tmp_stage in [\"early\",\"middle\" ,\"late\"]:\n",
        "\n",
        "        qry = \"\"\n",
        "        if tmp_stage == \"early\":\n",
        "            qry = \"drama_key == @tmp_key & phys_cnt < 4 \"\n",
        "\n",
        "        elif tmp_stage == \"middle\":\n",
        "            qry = \"drama_key == @tmp_key & 4< phys_cnt < 7 \"\n",
        "\n",
        "        else:\n",
        "            qry = \"drama_key == @tmp_key & phys_cnt >= 7 \"\n",
        "\n",
        "        target_i =  df_notnull.query(qry)[\"sharp_epg_hand_corrected\"]\n",
        "        epg_joined = str(df_notnull.query(qry)[\"sharp_epg_hand_corrected\"].values)\n",
        "\n",
        "        tmp_se = pd.Series( [ tmp_key, \"..title\" ,tmp_stage, epg_joined  ,\"love\", win_or_lose ]  , index=df_stage.columns  )\n",
        "        df_stage = df_stage.append( tmp_se, ignore_index=True )\n",
        "\n",
        "# early, middle, lateで作る\n",
        "\n",
        "# for i in range():\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPv0645OcmWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_stage\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-KXTCDwj-i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 空の列を足す\n",
        "df_stage[\"epg_tknz\"] = np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MHfP09qq0X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mecab = MeCab.Tagger()\n",
        "mecab.parse(\"\")\n",
        "for i, text in enumerate( df_stage['epg_joined']):\n",
        "    text_tokenized = []\n",
        "    # print(i)\n",
        "\n",
        "    # URL、記号などのゴミを取り除く\n",
        "    if type(text) is not str: \n",
        "        if np.isnan(text) :\n",
        "            continue \n",
        "    text = removeTrash(text)\n",
        "    node = mecab.parseToNode(text)\n",
        "    while node:\n",
        "        node = node.next\n",
        "        if node is None:\n",
        "            continue\n",
        "\n",
        "        if not node.feature.startswith(\"BOS/EOS\") and not node.feature.startswith(\"助詞\") and\\\n",
        "            not node.feature.startswith(\"記号\") and\\\n",
        "            node.feature.find(\"人名\") == -1 and\\\n",
        "            not node.feature.startswith(\"助動詞\"):\n",
        "            text_tokenized.append(node.surface)\n",
        "\n",
        "    df_stage[\"epg_tknz\"].iloc[i] = text_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZORc5o1Pco9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnokRMvd1fnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = vectorizer.fit_transform(\n",
        "    [str(i) for i in df_stage[\"epg_tknz\"].values]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGenqOWt1gPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62bm14bW1gqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mJ-vAUP1hDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer.idf_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sAUTzMn4s7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# idf値の確認\n",
        "\n",
        "idf = pd.Series(vectorizer.idf_, index=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ]) \\\n",
        "    .to_frame(\"idf\") \\\n",
        "    .sort_values(\"idf\", ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_nlKH7M4tTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "idf.iloc[1:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIR0JSNS4tsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ePCMx4Da-9I"
      },
      "source": [
        "## 形態素解析\n",
        "---\n",
        "\n",
        "MeCab を利用した形態素解析と、簡単な処理の例を示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0zHt5kiTa-9d"
      },
      "source": [
        "### 簡単な例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B_7wgWRsa-9l",
        "colab": {}
      },
      "source": [
        "# ※これは、演習用に単語文書行列を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
        "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qdvArrtWa-9o"
      },
      "source": [
        "CountVectorizer が生成する単語文書行列では、行 (横) 方向が1つの文書を表し、それぞれの列に単語の出現回数が格納されます (※単語文書行列と言った場合、列方向が文書を表す場合もあるので、他の文献を読む際は注意が必要です)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ilxvlhda-9o"
      },
      "source": [
        "どの列がどの単語と対応しているかを知るためには、vectorizer の vocabulary_ を参照します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQZkYzg_a-9p",
        "colab": {}
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-XZW_Vqa-9u"
      },
      "source": [
        "新しい文書に対しては、transform で変換します。\n",
        "\n",
        "なお、fit\\_transform の際に出てこなかった単語 (= vocabulary_ にない単語) については、行列内に登場しません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "spozm9-pa-9w",
        "colab": {}
      },
      "source": [
        "# transform も、リスト形式で与える必要があるので注意\n",
        "X_new = vectorizer.transform([\n",
        "    \"Hello I like this pen\"\n",
        "])\n",
        "X_new.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fUP0dONFa-9y"
      },
      "source": [
        "### 日本語データに適用\n",
        "前処理済みの日本語データに適用してみます。DataFrame にスペース区切りのテキストを準備している場合、DataFrame の列を参照させたものをそのまま与えることができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3XTvS-VKa-9z",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X = vectorizer.fit_transform(df[\"text_tokenized\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "syuYu8hga-91",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oVIavU0Xa-92",
        "colab": {}
      },
      "source": [
        "X[0].toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dvNzlApVa-95"
      },
      "source": [
        "↑この規模の単語文書行列になると、行列のサイズ (文書数x単語数) と比較し、値が入っている場所をほとんど無いことが分かります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fqtfcBd6a-96",
        "colab": {}
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bnDo6uFfa-97"
      },
      "source": [
        "　"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9T8K1Sba-97"
      },
      "source": [
        "## TF-IDF変換\n",
        "---\n",
        "\n",
        "TF-IDF 変換を行うと、単語の出現回数に、他の文書全体と比較した際の希少性 (レア度) で重みを付けることができます。\n",
        "\n",
        "TF-IDF 変換済みの単語文書行列は、`TfidfVectorizer` で作成できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ghxLSFzAa-98"
      },
      "source": [
        "### 簡単な例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "piBBAXK-a-98",
        "colab": {}
      },
      "source": [
        "# token_pattern は、デフォルトだと1文字の単語を除外するので、除外しないように設定する\n",
        "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwkRDYC7ylW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lr3yT8tXa-9-",
        "colab": {}
      },
      "source": [
        "# スペース区切りの文書をリストで与える\n",
        "X = vectorizer.fit_transform([\n",
        "    \"This is a pen\",\n",
        "    \"I am not a pen\",\n",
        "    \"Hello\"\n",
        "])\n",
        "X.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "of0bRS66a-9_",
        "colab": {}
      },
      "source": [
        "# ※これは、演習用に単語文書行列を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
        "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lwkAuD2oa--B"
      },
      "source": [
        "他の文書でも出現している単語については、同じ出現回数でも重みが低くなっていることが分かります。各単語の重みは、`idf_` で見ることができます。確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ImsppSXDa--C",
        "colab": {}
      },
      "source": [
        "vectorizer.idf_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7-QiVXs_a--E",
        "colab": {}
      },
      "source": [
        "# ※これは、演習用に IDF 値を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
        "pd.DataFrame(np.atleast_2d(vectorizer.idf_), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z35bpbtfa--F"
      },
      "source": [
        "デフォルトでは、各文書のノルムが1になるように正規化されています (norm=\"l2\")。確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z2Gle3k3a--G",
        "colab": {}
      },
      "source": [
        "np.linalg.norm(X.toarray(), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PiWBOEJ6a--J"
      },
      "source": [
        "### 日本語データに適用\n",
        "CountVectorizer の場合と同様に、前処理済みの日本語データに適用してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tcPEur6xa--J",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X = vectorizer.fit_transform(df[\"text_tokenized\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yB3krCe_a--L",
        "colab": {}
      },
      "source": [
        "X[0].toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exlfUKQYa--M"
      },
      "source": [
        "IDF 値の大きい単語・小さい単語を確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7SYAjaLOa--N",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# ※これは、演習用に IDF 値を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
        "pd.Series(vectorizer.idf_, index=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ]) \\\n",
        "    .to_frame(\"idf\") \\\n",
        "    .sort_values(\"idf\", ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AkVS36Cja--O"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-rYChGyna--O"
      },
      "source": [
        "## テキスト分類\n",
        "---\n",
        "定量化したテキスト情報を使うことで、テキストをカテゴリー別に分類してみましょう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JVGT1gv4a--P",
        "colab": {}
      },
      "source": [
        "# テストデータ\n",
        "df_test = pd.read_csv(\"dataset/wikipedia-test.txt\", sep=\"\\t\")\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JIAl91qja--Q"
      },
      "source": [
        "### 単語文書行列 (TF-IDF 適用済み) の作成\n",
        "単語文章行列を作成する前に、まずは文章を形態素解析します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTx-3037a--Q",
        "colab": {}
      },
      "source": [
        "mecab = MeCab.Tagger(\"-O wakati\")\n",
        "\n",
        "text_tokenized = []\n",
        "for text in df_test['text']:\n",
        "    text_tokenized.append(mecab.parse(text))\n",
        "    \n",
        "df_test['text_tokenized'] = text_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3v5MoEC4a--U"
      },
      "source": [
        "続いて、単語文章行列を学習データテストデータでそれぞれ生成します。<br>\n",
        "この時、2つの単語文章行列は同じ次元数でなければならないので、`transform`を使用します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OCvYhqiWa--V",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X = vectorizer.fit_transform(df[\"text_tokenized\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YGoM-SX2a--W",
        "colab": {}
      },
      "source": [
        "X_test = vectorizer.transform(df_test[\"text_tokenized\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S88NkqlQa--Z"
      },
      "source": [
        "### 分類器の適用・比較\n",
        "単語文書行列ができたら、後はこれまでやってきた機械学習と同様です。\n",
        "\n",
        "いくつかの分類器で、性能を比較してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXtCFjkja--a",
        "colab": {}
      },
      "source": [
        "# Accuracy, Precision/Recall/F-score/Support, Confusion Matrix を表示\n",
        "def show_evaluation_metrics(y_true, y_pred):\n",
        "    print(\"Accuracy:\")\n",
        "    print(accuracy_score(y_true, y_pred))\n",
        "    print()\n",
        "    \n",
        "    print(\"Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    \n",
        "    print(\"Confusion matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fT-t_hBma--b"
      },
      "source": [
        "### ロジスティック回帰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cTmFq6lma--d",
        "colab": {}
      },
      "source": [
        "clf_lr = LogisticRegression(n_jobs=-1)\n",
        "clf_lr.fit(X, df[\"category\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MInsT37Ha--f"
      },
      "source": [
        "推定結果は predict で得ることができます (他の分類器でも同様)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TXPjYVtQa--f",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "clf_lr.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g0m11vAla--g",
        "colab": {}
      },
      "source": [
        "y_test_pred = clf_lr.predict(X_test)\n",
        "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgstWu1sa--j"
      },
      "source": [
        "### SVM (線形カーネル)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g9cOBtQ4a--l",
        "colab": {}
      },
      "source": [
        "clf_svc = LinearSVC()\n",
        "clf_svc.fit(X, df[\"category\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GVEYwyxua--m",
        "colab": {}
      },
      "source": [
        "y_test_pred = clf_svc.predict(X_test)\n",
        "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G5fYOekxa--n"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nhbpiDg2a--n",
        "colab": {}
      },
      "source": [
        "clf_rf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
        "clf_rf.fit(X, df[\"category\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSc1ShwPa--p",
        "colab": {}
      },
      "source": [
        "y_test_pred = clf_rf.predict(X_test)\n",
        "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-IepwcsMa--r"
      },
      "source": [
        "　"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6oxDCnVRa--r"
      },
      "source": [
        "## 【演習1】\n",
        "上記いずれかのアルゴリズムのパラメータを変更して、分類精度を高めてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1bCd0XTqa--s",
        "colab": {}
      },
      "source": [
        "# Enter your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GoAMg4Rka--u"
      },
      "source": [
        "　"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CB2NQkE2a--w"
      },
      "source": [
        "### モデルの保存\n",
        "`pickle` でも保存できますが、`joblib` を使い、ファイル名末尾に `.gz`, `.bz2` 等を指定すると、自動的に圧縮してくれます。読み込み時も同様、自動的に解凍して読み込んでくれます。\n",
        "\n",
        "言語処理ではモデルが大容量になることが多いため、モデルの圧縮は重要です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hEgXmXvha--w",
        "colab": {}
      },
      "source": [
        "joblib.dump(clf_rf, \"wikipedia_category_classifier.pkl.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kh4d5bGPa--1"
      },
      "source": [
        "### モデル読み込みテスト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tDXcsBD8a--1",
        "colab": {}
      },
      "source": [
        "clf_rf_restored = joblib.load(\"wikipedia_category_classifier.pkl.gz\")\n",
        "clf_rf_restored"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6V5U9o3ha--2"
      },
      "source": [
        "読み込んだモデルは、上記ですでに学習済みなので、`predict`で予測が行えます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mgq0KeTwa--2",
        "colab": {}
      },
      "source": [
        "clf_rf_restored.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}