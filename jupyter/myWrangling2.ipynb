{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "\n",
    "import datetime\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import textwrap\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from graphviz import Digraph\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/viewing_rating.csv\", encoding='cp932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time型に\n",
    "df.start_at=pd.to_datetime(df.start_at)\n",
    "# averageの％を削除\n",
    "df[\"average\"] =  df[\"average\"].apply(lambda x : float(x[:-1]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"start_at_year\"] = df[\"start_at\"].dt.year\n",
    "df[\"start_at_month\"] = df[\"start_at\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"drama_key\"] = df.start_at.dt.strftime(\"%y\")+df.start_at.dt.strftime(\"%m\")+\"_\"+df.TV_station+\"_\"+df.time_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='../data/drama_info0115.json' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"../data/drama_info0115.json\", 'r')\n",
    "print(f)\n",
    "drama_info_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../data/drama_pre_stage.csv' does not exist: b'../data/drama_pre_stage.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-caa453080e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/drama_pre_stage.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cp932'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../data/drama_pre_stage.csv' does not exist: b'../data/drama_pre_stage.csv'"
     ]
    }
   ],
   "source": [
    "df_pre = pd.read_csv(\"../data/drama_pre_stage.csv\", encoding='cp932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = df_pre[[\"drama_key\" ,\"pre_part\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (textwrap.shorten(str(drama_info_json), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"main_actor1\"] = \"\"\n",
    "df[\"main_actor2\"] = \"\"\n",
    "df[\"original_work\"] = \"\"\n",
    "df[\"pre_part\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tmp_index in range(len(df)):\n",
    "    tmp_drama_key = df.iloc[tmp_index][\"drama_key\"]\n",
    "    if tmp_drama_key in drama_info_json.keys():\n",
    "#         print(drama_info_json[tmp_drama_key][\"main_actor1\"])\n",
    "        df[\"main_actor1\"][tmp_index] = drama_info_json[tmp_drama_key][\"main_actor1\"]\n",
    "        df[\"main_actor2\"][tmp_index] = drama_info_json[tmp_drama_key][\"main_actor2\"]\n",
    "        df[\"original_work\"][tmp_index] = drama_info_json[tmp_drama_key][\"original_work\"]\n",
    "        \n",
    "        if tmp_drama_key in df_pre.drama_key.values:\n",
    "            df[\"pre_part\"][tmp_index] = \\\n",
    "                df_pre[df_pre[\"drama_key\"] == tmp_drama_key][\"pre_part\"].values[0]\n",
    "#             float(df_pre[df_pre[\"drama_key\"] == tmp_drama_key][\"pre_part\"].values[0])\n",
    "#         else:\n",
    "#             print(tmp_drama_key)\n",
    "    \n",
    "    #         print(\"yes\"+tmp_drama_title)\n",
    "    else:\n",
    "        print(tmp_drama_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_person_key_df (actor_actress):\n",
    "    actor_actress_list = []\n",
    "    for column in actor_actress.columns:\n",
    "        if column == \"ranking\":\n",
    "            continue\n",
    "        actor_actress_list.extend(actor_actress[column].values.tolist())\n",
    "    print (\"元の数\"+ str(len(actor_actress_list)))\n",
    "    # uniqueにする\n",
    "    actor_actress_list = list(set(actor_actress_list))\n",
    "    #nan を除去\n",
    "    actor_actress_list = [actor for actor in actor_actress_list if type(actor) is not float ]\n",
    "    print (\"後の数\"+str(len(actor_actress_list)))\n",
    "\n",
    "    df_pivot = pd.DataFrame( columns=actor_actress_list, index=[str(n) for n in range(2008,2020)])\n",
    "\n",
    "    #pivot 形式に整形する\n",
    "    for tmp_name in df_pivot.columns:\n",
    "        for year in actor_actress.columns:\n",
    "            if year == \"ranking\": continue\n",
    "            if  len(actor_actress[actor_actress[year] == tmp_name].ranking) > 0:\n",
    "                df_pivot.loc[year][tmp_name] = (actor_actress[actor_actress[year] == tmp_name].ranking).values[0]\n",
    "    return (df_pivot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actress = pd.read_csv(\"../data/actress_power.csv\", encoding='cp932')\n",
    "df_actress_pivot = make_person_key_df(df_actress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor = pd.read_csv(\"../data/actor_power.csv\", encoding='cp932')\n",
    "df_actor_pivot = make_person_key_df(df_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actress_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor_namekey = df_actor_pivot.T.rename_axis('actor_actress').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actress_namekey = df_actress_pivot.T.rename_axis('actor_actress').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actress_namekey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, df_actor_namekey,left_on='main_actor1', right_on='actor_actress', how='left')\n",
    "#df_merged = pd.merge(df_merged, df_actress_namekey,left_on='main_actor1', right_on='actor_actress', how='right')\n",
    "#df_merged = pd.merge(df_merged, df_actress_namekey,left_on='main_actor2', right_on='actor_actress', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged = pd.merge(df_merged, df_actress_namekey,left_on='main_actor1', right_on='actor_actress', how='left'\n",
    "                     ,suffixes=('_1', '_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged = pd.merge(df_merged, df_actor_namekey,left_on='main_actor2', right_on='actor_actress', how='left'\n",
    "                     ,suffixes=('_3', '_4') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_merged, df_actress_namekey,left_on='main_actor2', right_on='actor_actress', how='left'\n",
    "                    , suffixes=('_3', '_4'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged[[\"main_actor1\",\"2017\",\"2016\",\"2014\"]]\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[:,df_merged.columns.str.contains('20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years = df_merged[df_merged[\"start_at\"] > datetime.datetime.strptime(\"2011-01-01\", '%Y-%m-%d')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years[\"main_actor1_rank\"] = np.nan\n",
    "df_new8years[\"main_actor2_rank\"] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_new8years)):\n",
    "    prev_year = df_new8years[\"start_at\"].dt.year.iloc[i] - 1 \n",
    "    df_filter = df_new8years.loc[:,df_new8years.columns.str.contains(str(prev_year))]\n",
    "#   import pdb;pdb.set_trace()\n",
    "    \n",
    "    prev_year1 = str(prev_year) + \"_1\"\n",
    "    prev_year2 = str(prev_year) + \"_2\"\n",
    "    prev_year3 = str(prev_year) + \"_3\"\n",
    "    prev_year4 = str(prev_year) + \"_4\"\n",
    "#     import pdb; pdb.set_trace()\n",
    "    for j in range(len(df_filter)):\n",
    "        tmp1 =  0 if np.isnan(df_filter[prev_year1].iloc[j]) else df_filter[prev_year1].iloc[j]\n",
    "        tmp2 =  0 if np.isnan(df_filter[prev_year2].iloc[j]) else df_filter[prev_year2].iloc[j]\n",
    "        tmp3 =  0 if np.isnan(df_filter[prev_year3].iloc[j]) else df_filter[prev_year3].iloc[j]\n",
    "        tmp4 =  0 if np.isnan(df_filter[prev_year4].iloc[j]) else df_filter[prev_year4].iloc[j]\n",
    "#         import pdb; pdb.set_trace()\n",
    "        df_new8years[\"main_actor1_rank\"].iloc[j] =   tmp1 + tmp2 if (tmp1 + tmp2 != 0) else np.nan\n",
    "        df_new8years[\"main_actor2_rank\"].iloc[j] =   tmp3 + tmp4 if (tmp3 + tmp4 != 0) else np.nan\n",
    "#         print(dbg)\n",
    "#     df_filter[prev_year + \"_2\"]\n",
    "#    if  np.isnan(df_filter[\"2018_1\"]) or np.isnan(df_filter[\"2018_2\"])  :\n",
    "#        print(\"come\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new8years[\"main_actor1_rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new8years[\"main_actor2_rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_episode = df_new8years.loc[:, df_new8years.columns.str.contains(\"Epi\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years[\"average_calc\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averageを計算してみたが、もともとあるaverageが加重平均だったので、そちらを採用することに\n",
    "for i in  range(len(df_episode)):\n",
    "    vr_sum = 0\n",
    "    for epi_i, col in  enumerate(df_episode.columns):\n",
    "        if df_episode[col].iloc[i] == \"-\"  :\n",
    "            if epi_i == 0:\n",
    "#                 print (col+\"_\"+str(epi_i))\n",
    "                break\n",
    "            df_new8years[\"average_calc\"].iloc[i] = vr_sum/epi_i\n",
    "            break\n",
    "        vr_sum += float(df_episode[col].iloc[i])\n",
    "        if epi_i == 14 : df_new8years[\"average_calc\"].iloc[i] = vr_sum / 15\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM数も特徴量に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.read_csv(\"../data/number_of_cm.csv\", encoding='cp932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm[\"name_ns\"] = df_cm.name.str.replace('\\s','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_pivot = pd.DataFrame(index = set(df_cm.name_ns.values),columns = range(1990,2019)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_name in set(df_cm.name_ns.values):\n",
    "    for t_year in range(1990,2019):\n",
    "        \n",
    "#         tmp_q = f\"name_ns == '{t_name}' & year == '{t_year}' \" \n",
    "        tmp_q = \"name_ns == @t_name & year == @t_year \" \n",
    "# print(tmp_q)\n",
    "        try :\n",
    "            tmp_df = df_cm.query(tmp_q)\n",
    "    #             print(f'{tmp_df[\"number_of_cm\"].values} タレント{t_name},{t_year}年')\n",
    "            if tmp_df[\"number_of_cm\"].values:\n",
    "#                 print(f'{tmp_df[\"number_of_cm\"].values} タレント{t_name},{t_year}年')\n",
    "                df_cm_pivot.loc[t_name,t_year] = int(tmp_df[\"number_of_cm\"].values)\n",
    "        except KeyError as instance:\n",
    "            print (instance)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_pivot = df_cm_pivot.rename_axis(\"actor_actress\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_arr = df_actor_namekey.actor_actress.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_arr.extend(df_actress_namekey.actor_actress.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 表示の確認\n",
    "# for t_n in df_cm_pivot[\"actor_actress\"].values:\n",
    "#     if t_n in rank_arr: print(t_n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前の枠の数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years[\"pre_slot_vr_average\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_for_nan = sum(df_new8years.average)/len(df_new8years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tmp_idx in range(len(df_new8years)):\n",
    "    if df_new8years[\"start_at_month\"].iloc[tmp_idx] == 1:\n",
    "        pre_slot_month = str(10) \n",
    "        pre_slot_year = df_new8years[\"start_at_year\"].iloc[tmp_idx] - 1\n",
    "    else:\n",
    "        pre_slot_month = \"0\"+ str(int(df_new8years[\"start_at_month\"].iloc[tmp_idx]) - 3) \n",
    "        pre_slot_year = df_new8years[\"start_at_year\"].iloc[tmp_idx]\n",
    "        \n",
    "    time_table = df_new8years[\"time_table\"].iloc[tmp_idx]\n",
    "    TV_station = df_new8years[\"TV_station\"].iloc[tmp_idx]\n",
    "#     print(f\"{pre_slot_year%2000}{pre_slot_month}_{time_table}_{TV_station} \")\n",
    "    pre_key =  str(pre_slot_year%2000) + pre_slot_month+\"_\"+TV_station+\"_\"+time_table\n",
    "    try:\n",
    "        if pre_key in df[\"drama_key\"].values:\n",
    "            tmp_pre_slot_vr_average = float(df[df[\"drama_key\"]==pre_key].average) \n",
    "        else:\n",
    "            tmp_pre_slot_vr_average = val_for_nan\n",
    "#         print(pre_key)\n",
    "    except:\n",
    "        print(pre_key)\n",
    "        tmp_pre_slot_vr_average = float(df[df[\"drama_key\"]==pre_key].average.values[0])\n",
    "    \n",
    "    print(tmp_pre_slot_vr_average)\n",
    "    \n",
    "    df_new8years[\"pre_slot_vr_average\"].iloc[tmp_idx] = tmp_pre_slot_vr_average\n",
    "#         float(df[df[\"drama_key\"]==pre_key].average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new8years [df_new8years[\"drama_key\"] == \"1504_TBS_木21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 俳優ランクを人気ポイントに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years[\"main_actor1_pt\"] = df_new8years[\"main_actor1_rank\"].apply(lambda x : 40 - x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years[\"main_actor2_pt\"] = df_new8years[\"main_actor2_rank\"].apply(lambda x : 40 - x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years[\"main_actor1_pt\"] = df_new8years[\"main_actor1_pt\"].fillna(0)\n",
    "df_new8years[\"main_actor2_pt\"] = df_new8years[\"main_actor2_pt\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years[\"has_original_work\"] = df_new8years[\"original_work\"].apply(lambda x : \"\" if x ==\"\" else True ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) CM数も特徴量に加工する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hotエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years = pd.get_dummies(df_new8years, columns=[\"TV_station\", \"start_at_month\", \"start_at_year\",\"has_original_work\",\"time_table\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikiの俳優情報を特徴量として"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/actor_wiki0220.json\", 'r')\n",
    "print(f)\n",
    "actor_wiki_json = json.load(f)\n",
    "df_actor_wiki = pd.read_excel(\"../data/wiki_raw.xlsx\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor_wiki[df_actor_wiki[\"office\"] == \"ジャニーズ事務所[4]\"][\"office\"] = \"ジャニーズ事務所\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx = df_actor_wiki[df_actor_wiki[\"office\"] == \"ジャニーズ事務所[4]\"].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor_wiki[\"office\"].iloc[target_idx] = \"ジャニーズ事務所\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor_wiki.iloc[target_idx][\"office\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jかどうか\n",
    "df_actor_wiki[\"isj\"] = df_actor_wiki[\"office\"] == \"ジャニーズ事務所\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new8years[\"actor1_office\"] = np.nan\n",
    "# df_new8years[\"actor2_office\"] = np.nan\n",
    "# df_new8years[\"actor1_birthday\"] = np.nan\n",
    "# df_new8years[\"actor2_birthday\"] = np.nan\n",
    "df_new8years[\"actor1_isj\"] = 0\n",
    "df_new8years[\"actor2_isj\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(df_new8years)):\n",
    "    actor1 = df_new8years[\"main_actor1\"].iloc[idx]\n",
    "    actor2 = df_new8years[\"main_actor2\"].iloc[idx]\n",
    "    \n",
    "#     print(df_actor_wiki[df_actor_wiki[\"actor_name\"] == actor1].isj)\n",
    "    \n",
    "    if actor1 in  df_actor_wiki[\"actor_name\"].values :\n",
    "        df_new8years[\"actor1_isj\"].iloc[idx] = \\\n",
    "            int(df_actor_wiki[df_actor_wiki[\"actor_name\"] == actor1].isj.values[0])\n",
    "    \n",
    "    if actor2 in  df_actor_wiki[\"actor_name\"].values :\n",
    "        df_new8years[\"actor2_isj\"].iloc[idx] = \\\n",
    "            int(df_actor_wiki[df_actor_wiki[\"actor_name\"] == actor2].isj.values[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years[df_new8years[\"actor1_isj\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(len(df_new8years)):\n",
    "#     actor1 = df_new8years[\"main_actor1\"].iloc[idx]\n",
    "#     actor2 = df_new8years[\"main_actor2\"].iloc[idx]\n",
    "# #     print(actor1)\n",
    "    \n",
    "#     if actor_wiki_json[actor1]:\n",
    "    \n",
    "#         df_new8years[\"actor1_office\"].iloc[idx] = actor_wiki_json[actor1].get(\"office\")\n",
    "#         df_new8years[\"actor1_birthday\"].iloc[idx] = actor_wiki_json[actor1].get(\"birthday\")\n",
    "    \n",
    "#     if actor_wiki_json[actor2]:\n",
    "#         df_new8years[\"actor2_office\"].iloc[idx] = actor_wiki_json[actor2].get(\"office\")\n",
    "#         df_new8years[\"actor2_birthday\"].iloc[idx] = actor_wiki_json[actor2].get(\"birthday\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new8years[[\"main_actor1_pt\" , \"main_actor2_pt\", \"actor1_isj\",\"actor2_isj\", \\\n",
    "                  \"pre_part\",\"pre_slot_vr_average\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummys = df_new8years.loc[:,df_new8years.columns.str.contains(('start_at_year_|TV_station_|start_at_month_|has_original_work|time_table'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,X_dummys], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_new8years[\"average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1234 )\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=12345 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=lm.fit(X_train,y_train)\n",
    "#predictions=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    a = y_test.values[i]\n",
    "    b = y_pred[i]\n",
    "    c = df_new8years.iloc[y_test.index[i]].drama_title\n",
    "    print(f'{c}\\t 視聴率：実際 {a}   \\t 予測 {b} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    a = y_test.values[i]\n",
    "    b = y_pred[i]\n",
    "    c = df_new8years.iloc[y_test.index[i]].drama_title\n",
    "    if abs (a-b) > 3:\n",
    "        print(f'{c}\\t 視聴率：実際 {a}   \\t 予測 {b} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len (X.columns)):\n",
    "    print(f\"\"\"{i}  回帰係数 {X.columns[i]}\\t{model.coef_[i]} \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('モデル関数の切片 w2: %.3f' %model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('決定係数 R^2： ', model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# print (f\"rmse: {lm_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル２決定木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = DecisionTreeRegressor(max_depth = 3)\n",
    "clf = DecisionTreeRegressor(max_leaf_nodes= 14)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_tree))\n",
    "print (rf_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len (X.columns)):\n",
    "    print(f\"\"\"{i}  FI {X.columns[i]}     \\t{clf.feature_importances_[i]} \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    a = y_test.values[i]\n",
    "    b = y_pred[i]\n",
    "    print(f'視聴率：実際 {a}   \\t 予測 {b} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(\n",
    "    clf,\n",
    "    out_file=None,\n",
    "    feature_names=X.columns,\n",
    "    class_names=\"average\",\n",
    "    filled=True,\n",
    "    proportion=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new8years.to_csv(\"../data/hoge.csv\", encoding =\"cp932\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
