{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/c-c-c-c/dm_integration/blob/master/myMecab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8Oh-JGka-8_"
   },
   "source": [
    "# テキストの分類\n",
    "テキスト分類は、以下の順に行います。\n",
    "\n",
    "1. 前処理\n",
    "2. 数値表現化 (CountVectorizer, TfIdfVectorizer)\n",
    "3. 分類器を学習\n",
    "\n",
    "本ノートブックでは、Wikipedia のエントリ分類を通じて、テキスト分類器を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
<<<<<<< HEAD
     "base_uri": "https://localhost:8080/",
     "height": 121
=======
      "name": "myMecab",
      "provenance": [],
      "collapsed_sections": [
        "TYMmznRYa-9Q",
        "0zHt5kiTa-9d",
        "fUP0dONFa-9y",
        "ghxLSFzAa-98",
        "PiWBOEJ6a--J",
        "JIAl91qja--Q",
        "S88NkqlQa--Z",
        "fT-t_hBma--b",
        "zgstWu1sa--j",
        "G5fYOekxa--n",
        "CB2NQkE2a--w",
        "kh4d5bGPa--1"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "2qkpjTGlYJdq",
    "outputId": "50de1d46-f92a-4a01-da92-4c9282975825"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
<<<<<<< HEAD
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
=======
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-c-c-c/dm_integration/blob/master/myMecab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R8Oh-JGka-8_"
      },
      "source": [
        "# テキストの分類\n",
        "テキスト分類は、以下の順に行います。\n",
        "\n",
        "1. 前処理\n",
        "2. 数値表現化 (CountVectorizer, TfIdfVectorizer)\n",
        "3. 分類器を学習\n",
        "\n",
        "本ノートブックでは、Wikipedia のエントリ分類を通じて、テキスト分類器を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qkpjTGlYJdq",
        "colab_type": "code",
        "outputId": "f0f317a0-e935-4ab2-ca71-749e0ec8ec18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P-6WpdMM7ywT",
        "outputId": "037b5b86-0d86-46ca-960e-fdcc4885ccf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.5)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.8)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.3)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.5)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.8)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.3)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Requirement already satisfied: mecab-python3==0.7 in /usr/local/lib/python3.6/dist-packages (0.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPKMuQKTFTGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e11e4830-201e-45aa-eac7-39217afee063"
      },
      "source": [
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'mecab-ipadic-neologd' already exists and is not an empty directory.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : Check the existance of libraries\n",
            "[install-mecab-ipadic-NEologd] :     find => ok\n",
            "[install-mecab-ipadic-NEologd] :     sort => ok\n",
            "[install-mecab-ipadic-NEologd] :     head => ok\n",
            "[install-mecab-ipadic-NEologd] :     cut => ok\n",
            "[install-mecab-ipadic-NEologd] :     egrep => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab-config => ok\n",
            "[install-mecab-ipadic-NEologd] :     make => ok\n",
            "[install-mecab-ipadic-NEologd] :     curl => ok\n",
            "[install-mecab-ipadic-NEologd] :     sed => ok\n",
            "[install-mecab-ipadic-NEologd] :     cat => ok\n",
            "[install-mecab-ipadic-NEologd] :     diff => ok\n",
            "[install-mecab-ipadic-NEologd] :     tar => ok\n",
            "[install-mecab-ipadic-NEologd] :     unxz => ok\n",
            "[install-mecab-ipadic-NEologd] :     xargs => ok\n",
            "[install-mecab-ipadic-NEologd] :     grep => ok\n",
            "[install-mecab-ipadic-NEologd] :     iconv => ok\n",
            "[install-mecab-ipadic-NEologd] :     patch => ok\n",
            "[install-mecab-ipadic-NEologd] :     which => ok\n",
            "[install-mecab-ipadic-NEologd] :     file => ok\n",
            "[install-mecab-ipadic-NEologd] :     openssl => ok\n",
            "[install-mecab-ipadic-NEologd] :     awk => ok\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd is already up-to-date\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd will be install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Make mecab-ipadic-NEologd\n",
            "[make-mecab-ipadic-NEologd] : Start..\n",
            "[make-mecab-ipadic-NEologd] : Check local seed directory\n",
            "[make-mecab-ipadic-NEologd] : Check local seed file\n",
            "[make-mecab-ipadic-NEologd] : Check local build directory\n",
            "[make-mecab-ipadic-NEologd] : Download original mecab-ipadic file\n",
            "[make-mecab-ipadic-NEologd] : Original mecab-ipadic file is already there.\n",
            "[make-mecab-ipadic-NEologd] : Decompress original mecab-ipadic file\n",
            "[make-mecab-ipadic-NEologd] : Delete old mecab-ipadic-2.7.0-20070801-neologd-20200130 directory\n",
            "mecab-ipadic-2.7.0-20070801/\n",
            "mecab-ipadic-2.7.0-20070801/README\n",
            "mecab-ipadic-2.7.0-20070801/AUTHORS\n",
            "mecab-ipadic-2.7.0-20070801/COPYING\n",
            "mecab-ipadic-2.7.0-20070801/ChangeLog\n",
            "mecab-ipadic-2.7.0-20070801/INSTALL\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.am\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.in\n",
            "mecab-ipadic-2.7.0-20070801/NEWS\n",
            "mecab-ipadic-2.7.0-20070801/aclocal.m4\n",
            "mecab-ipadic-2.7.0-20070801/config.guess\n",
            "mecab-ipadic-2.7.0-20070801/config.sub\n",
            "mecab-ipadic-2.7.0-20070801/configure\n",
            "mecab-ipadic-2.7.0-20070801/configure.in\n",
            "mecab-ipadic-2.7.0-20070801/install-sh\n",
            "mecab-ipadic-2.7.0-20070801/missing\n",
            "mecab-ipadic-2.7.0-20070801/mkinstalldirs\n",
            "mecab-ipadic-2.7.0-20070801/Adj.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adnominal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adverb.csv\n",
            "mecab-ipadic-2.7.0-20070801/Auxil.csv\n",
            "mecab-ipadic-2.7.0-20070801/Conjunction.csv\n",
            "mecab-ipadic-2.7.0-20070801/Filler.csv\n",
            "mecab-ipadic-2.7.0-20070801/Interjection.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adjv.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adverbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.demonst.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.nai.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.name.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.number.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.org.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.place.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.proper.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.verbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp-col.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp.csv\n",
            "mecab-ipadic-2.7.0-20070801/Prefix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Suffix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Symbol.csv\n",
            "mecab-ipadic-2.7.0-20070801/Verb.csv\n",
            "mecab-ipadic-2.7.0-20070801/char.def\n",
            "mecab-ipadic-2.7.0-20070801/feature.def\n",
            "mecab-ipadic-2.7.0-20070801/left-id.def\n",
            "mecab-ipadic-2.7.0-20070801/matrix.def\n",
            "mecab-ipadic-2.7.0-20070801/pos-id.def\n",
            "mecab-ipadic-2.7.0-20070801/rewrite.def\n",
            "mecab-ipadic-2.7.0-20070801/right-id.def\n",
            "mecab-ipadic-2.7.0-20070801/unk.def\n",
            "mecab-ipadic-2.7.0-20070801/dicrc\n",
            "mecab-ipadic-2.7.0-20070801/RESULT\n",
            "[make-mecab-ipadic-NEologd] : Configure custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200130\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for working aclocal-1.4... missing\n",
            "checking for working autoconf... missing\n",
            "checking for working automake-1.4... missing\n",
            "checking for working autoheader... missing\n",
            "checking for working makeinfo... missing\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking for mecab-config... /usr/bin/mecab-config\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "[make-mecab-ipadic-NEologd] : Encode the character encoding of system dictionary resources from EUC_JP to UTF-8\n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.demonst.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adjv.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.nai.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adnominal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.place.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Symbol.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.number.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp-col.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.proper.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.verbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Prefix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Verb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adverb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Suffix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Interjection.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Filler.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adverbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.org.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Auxil.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.name.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adj.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Conjunction.csv \n",
            "rm ./Noun.demonst.csv \n",
            "rm ./Noun.adjv.csv \n",
            "rm ./Noun.nai.csv \n",
            "rm ./Noun.csv \n",
            "rm ./Postp.csv \n",
            "rm ./Adnominal.csv \n",
            "rm ./Noun.place.csv \n",
            "rm ./Others.csv \n",
            "rm ./Symbol.csv \n",
            "rm ./Noun.number.csv \n",
            "rm ./Postp-col.csv \n",
            "rm ./Noun.proper.csv \n",
            "rm ./Noun.verbal.csv \n",
            "rm ./Prefix.csv \n",
            "rm ./Verb.csv \n",
            "rm ./Adverb.csv \n",
            "rm ./Suffix.csv \n",
            "rm ./Interjection.csv \n",
            "rm ./Filler.csv \n",
            "rm ./Noun.adverbal.csv \n",
            "rm ./Noun.org.csv \n",
            "rm ./Auxil.csv \n",
            "rm ./Noun.name.csv \n",
            "rm ./Noun.others.csv \n",
            "rm ./Adj.csv \n",
            "rm ./Conjunction.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./left-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./feature.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./matrix.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./unk.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./right-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./rewrite.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./pos-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./char.def \n",
            "rm ./left-id.def \n",
            "rm ./feature.def \n",
            "rm ./matrix.def \n",
            "rm ./unk.def \n",
            "rm ./right-id.def \n",
            "rm ./rewrite.def \n",
            "rm ./pos-id.def \n",
            "rm ./char.def \n",
            "mv ./Interjection.csv.utf8 ./Interjection.csv \n",
            "mv ./matrix.def.utf8 ./matrix.def \n",
            "mv ./Noun.place.csv.utf8 ./Noun.place.csv \n",
            "mv ./right-id.def.utf8 ./right-id.def \n",
            "mv ./Postp.csv.utf8 ./Postp.csv \n",
            "mv ./Adnominal.csv.utf8 ./Adnominal.csv \n",
            "mv ./Adverb.csv.utf8 ./Adverb.csv \n",
            "mv ./Auxil.csv.utf8 ./Auxil.csv \n",
            "mv ./Adj.csv.utf8 ./Adj.csv \n",
            "mv ./Others.csv.utf8 ./Others.csv \n",
            "mv ./Noun.demonst.csv.utf8 ./Noun.demonst.csv \n",
            "mv ./Noun.nai.csv.utf8 ./Noun.nai.csv \n",
            "mv ./Noun.number.csv.utf8 ./Noun.number.csv \n",
            "mv ./Symbol.csv.utf8 ./Symbol.csv \n",
            "mv ./Filler.csv.utf8 ./Filler.csv \n",
            "mv ./Noun.proper.csv.utf8 ./Noun.proper.csv \n",
            "mv ./Noun.verbal.csv.utf8 ./Noun.verbal.csv \n",
            "mv ./Noun.csv.utf8 ./Noun.csv \n",
            "mv ./pos-id.def.utf8 ./pos-id.def \n",
            "mv ./Conjunction.csv.utf8 ./Conjunction.csv \n",
            "mv ./unk.def.utf8 ./unk.def \n",
            "mv ./Noun.org.csv.utf8 ./Noun.org.csv \n",
            "mv ./feature.def.utf8 ./feature.def \n",
            "mv ./Noun.others.csv.utf8 ./Noun.others.csv \n",
            "mv ./Prefix.csv.utf8 ./Prefix.csv \n",
            "mv ./char.def.utf8 ./char.def \n",
            "mv ./Postp-col.csv.utf8 ./Postp-col.csv \n",
            "mv ./Noun.name.csv.utf8 ./Noun.name.csv \n",
            "mv ./Verb.csv.utf8 ./Verb.csv \n",
            "mv ./left-id.def.utf8 ./left-id.def \n",
            "mv ./rewrite.def.utf8 ./rewrite.def \n",
            "mv ./Noun.adjv.csv.utf8 ./Noun.adjv.csv \n",
            "mv ./Suffix.csv.utf8 ./Suffix.csv \n",
            "mv ./Noun.adverbal.csv.utf8 ./Noun.adverbal.csv \n",
            "[make-mecab-ipadic-NEologd] : Fix yomigana field of IPA dictionary\n",
            "patching file Noun.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Verb.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.adverbal.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.others.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Prefix.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.demonst.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "[make-mecab-ipadic-NEologd] : Copy user dictionary resource\n",
            "[make-mecab-ipadic-NEologd] : Install adverb entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adverb-dict-seed.20150623.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install interjection entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-interjection-dict-seed.20170216.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-common-noun-ortho-variant-dict-seed.20170228.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-proper-noun-ortho-variant-dict-seed.20161110.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of orthographic variant of a noun used as verb form using /content/mecab-ipadic-neologd/libexec/../seed/neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install frequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-std-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-exp-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install adjective verb orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-verb-dict-seed.20160324.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent datetime representation entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-date-time-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent quantity representation entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-quantity-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of ill formed words using /content/mecab-ipadic-neologd/libexec/../seed/neologd-ill-formed-words-dict-seed.20170127.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Re-Index system dictionary\n",
            "reading ./unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "reading ./Noun.demonst.csv ... 120\n",
            "reading ./Noun.adjv.csv ... 3328\n",
            "reading ./Noun.nai.csv ... 42\n",
            "reading ./neologd-date-time-infreq-dict-seed.20190415.csv ... 16866\n",
            "reading ./neologd-ill-formed-words-dict-seed.20170127.csv ... 60616\n",
            "reading ./neologd-adjective-std-dict-seed.20151126.csv ... 507812\n",
            "reading ./Noun.csv ... 60734\n",
            "reading ./Postp.csv ... 146\n",
            "reading ./Adnominal.csv ... 135\n",
            "reading ./neologd-interjection-dict-seed.20170216.csv ... 4701\n",
            "reading ./Noun.place.csv ... 73194\n",
            "reading ./Others.csv ... 2\n",
            "reading ./Symbol.csv ... 208\n",
            "reading ./Noun.number.csv ... 42\n",
            "reading ./Postp-col.csv ... 91\n",
            "reading ./Noun.proper.csv ... 27493\n",
            "reading ./Noun.verbal.csv ... 12150\n",
            "reading ./Prefix.csv ... 224\n",
            "reading ./Verb.csv ... 130750\n",
            "reading ./neologd-adjective-exp-dict-seed.20151126.csv ... 1051146\n",
            "reading ./neologd-adverb-dict-seed.20150623.csv ... 139792\n",
            "reading ./Adverb.csv ... 3032\n",
            "reading ./Suffix.csv ... 1448\n",
            "reading ./Interjection.csv ... 252\n",
            "reading ./Filler.csv ... 19\n",
            "reading ./Noun.adverbal.csv ... 808\n",
            "reading ./Noun.org.csv ... 17149\n",
            "reading ./Auxil.csv ... 199\n",
            "reading ./neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv ... 26058\n",
            "reading ./neologd-proper-noun-ortho-variant-dict-seed.20161110.csv ... 138379\n",
            "reading ./Noun.name.csv ... 34215\n",
            "reading ./Noun.others.csv ... 153\n",
            "reading ./neologd-common-noun-ortho-variant-dict-seed.20170228.csv ... 152869\n",
            "reading ./neologd-adjective-verb-dict-seed.20160324.csv ... 20268\n",
            "reading ./Adj.csv ... 27210\n",
            "reading ./mecab-user-dict-seed.20200130.csv ... 3179078\n",
            "reading ./Conjunction.csv ... 171\n",
            "reading ./neologd-quantity-infreq-dict-seed.20190415.csv ... 229216\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "[make-mecab-ipadic-NEologd] : Make custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200130\n",
            "make: Nothing to be done for 'all'.\n",
            "[make-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Get results of tokenize test\n",
            "[test-mecab-ipadic-NEologd] : Start..\n",
            "[test-mecab-ipadic-NEologd] : Replace timestamp from 'git clone' date to 'git commit' date\n",
            "[test-mecab-ipadic-NEologd] : Get buzz phrases\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1401  100  1401    0     0   1863      0 --:--:-- --:--:-- --:--:--  1860\n",
            "[test-mecab-ipadic-NEologd] : Get difference between default system dictionary and mecab-ipadic-NEologd\n",
            "[test-mecab-ipadic-NEologd] : Tokenize phrase using default system dictionary\n",
            "[test-mecab-ipadic-NEologd] : Tokenize phrase using mecab-ipadic-NEologd\n",
            "[test-mecab-ipadic-NEologd] : Get result of diff\n",
            "[test-mecab-ipadic-NEologd] : Please check difference between default system dictionary and mecab-ipadic-NEologd\n",
            "\n",
            "default system dictionary\t  |\tmecab-ipadic-NEologd\n",
            "青 ガエル \t\t\t  |\t青ガエル \n",
            "佐野 康之 \t\t\t  |\t佐野康之 \n",
            "唐 田 \t\t\t\t  |\t唐田 \n",
            "草 彅 \t\t\t\t  |\t草彅 \n",
            "草なぎ 剛 \t\t\t  |\t草なぎ剛 \n",
            "はんじ ょう \t\t\t  |\tはん じょう \n",
            "近鉄 南大阪線 \t\t\t  |\t近鉄南大阪線 \n",
            "表彰 式 \t\t\t  |\t表彰式 \n",
            "\n",
            "[test-mecab-ipadic-NEologd] : Finish..\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Please check the list of differences in the upper part.\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Do you want to install mecab-ipadic-NEologd? Type yes or no.\n",
            "[install-mecab-ipadic-NEologd] : OK. Let's install mecab-ipadic-NEologd.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : /usr/lib/x86_64-linux-gnu/mecab/dic is current user's directory\n",
            "[install-mecab-ipadic-NEologd] : Make install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "make[1]: Entering directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200130'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            "/bin/bash ./mkinstalldirs /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            " /usr/bin/install -c -m 644 ./matrix.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/matrix.bin\n",
            " /usr/bin/install -c -m 644 ./char.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/char.bin\n",
            " /usr/bin/install -c -m 644 ./sys.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/sys.dic\n",
            " /usr/bin/install -c -m 644 ./unk.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/unk.dic\n",
            " /usr/bin/install -c -m 644 ./left-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/left-id.def\n",
            " /usr/bin/install -c -m 644 ./right-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/right-id.def\n",
            " /usr/bin/install -c -m 644 ./rewrite.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/rewrite.def\n",
            " /usr/bin/install -c -m 644 ./pos-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/pos-id.def\n",
            " /usr/bin/install -c -m 644 ./dicrc /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/dicrc\n",
            "make[1]: Leaving directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200130'\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Install completed.\n",
            "[install-mecab-ipadic-NEologd] : When you use MeCab, you can set '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd' as a value of '-d' option of MeCab.\n",
            "[install-mecab-ipadic-NEologd] : Usage of mecab-ipadic-NEologd is here.\n",
            "Usage:\n",
            "    $ mecab -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd ...\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ahF2OfXfa-9B",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "import MeCab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DUHMMXZRa-9E"
      },
      "source": [
        "## データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YCwAqWLba-9F",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# タブ (\\t) 区切りファイルを読み込む\n",
        "df = pd.read_csv(\"./drive/My Drive/0_インテグ作業/data/EPG_checking (1).csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN9Ikeaa990W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"sharp_detail_epg_tknz\"] = np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnkQyB7YtinW",
        "colab_type": "code",
        "outputId": "da0560e0-41f5-4f98-9bdc-97e811a31651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>drama_key</th>\n",
              "      <th>drama_title</th>\n",
              "      <th>sharp_title</th>\n",
              "      <th>sharp_num_cnt</th>\n",
              "      <th>sharp_num_epg</th>\n",
              "      <th>start_time</th>\n",
              "      <th>sharp_detail_epg</th>\n",
              "      <th>sharp_detail_epg_tknz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1910_CX_月21</td>\n",
              "      <td>シャーロック</td>\n",
              "      <td>番組名シャーロック【危険な天才探偵×スマートな医師ー今夜、運命の出逢い】　#01</td>\n",
              "      <td>1</td>\n",
              "      <td>['#01']</td>\n",
              "      <td>['21', '22']</td>\n",
              "      <td>番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1910_CX_月21</td>\n",
              "      <td>シャーロック</td>\n",
              "      <td>番組名シャーロック【探偵×医師最強バディ始動!天才VS聖女の謎解き心理戦】　#02</td>\n",
              "      <td>2</td>\n",
              "      <td>['#02']</td>\n",
              "      <td>['21', '22']</td>\n",
              "      <td>番組詳細「FIVBワールドカップバレーボール2019　男子　日本×ブラジル」延長の際、放送時...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1910_CX_月21</td>\n",
              "      <td>シャーロック</td>\n",
              "      <td>番組名シャーロック【天才VS詐欺師の騙し合い!ノンストップのどんでん返し】　#03</td>\n",
              "      <td>3</td>\n",
              "      <td>['#03']</td>\n",
              "      <td>['21', '21']</td>\n",
              "      <td>番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1910_CX_月21</td>\n",
              "      <td>シャーロック</td>\n",
              "      <td>番組名シャーロック【試合直前に消えたボクシング世界王者!オレンジの傘の謎】　#04</td>\n",
              "      <td>4</td>\n",
              "      <td>['#04']</td>\n",
              "      <td>['21', '21']</td>\n",
              "      <td>番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1910_CX_月21</td>\n",
              "      <td>シャーロック</td>\n",
              "      <td>番組名シャーロック【歩く死体の謎!熱帯魚と母の愛…その真相、正義か狂気か】　#05</td>\n",
              "      <td>5</td>\n",
              "      <td>['#05']</td>\n",
              "      <td>['21', '21']</td>\n",
              "      <td>番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7662</th>\n",
              "      <td>7662</td>\n",
              "      <td>0710_TBS_日21</td>\n",
              "      <td>ハタチの恋人</td>\n",
              "      <td>番組名ハタチの恋人「運命の再会」</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['21', '21']</td>\n",
              "      <td>番組詳細レストランに向かった圭祐(明石家さんま)は、かつて交際していた絵里(小泉今日子)と再...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7663</th>\n",
              "      <td>7663</td>\n",
              "      <td>0710_TBS_日21</td>\n",
              "      <td>ハタチの恋人</td>\n",
              "      <td>番組名ハタチの恋人「バージンロード」</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['21', '21']</td>\n",
              "      <td>番組詳細ユリ(長沢まさみ)は、由紀夫(塚本高史)の父親に会うと約束した日に、圭祐(明石家さん...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7664</th>\n",
              "      <td>7664</td>\n",
              "      <td>0707_CX_月21</td>\n",
              "      <td>ファースト・キス</td>\n",
              "      <td>番組名ファースト・キス</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['21', '21']</td>\n",
              "      <td>番組詳細ファースト・キス◇秋生（平岡祐太）への思いを捨て、ロサンゼルスに帰ることを決意した美...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7665</th>\n",
              "      <td>7665</td>\n",
              "      <td>0707_CX_月21</td>\n",
              "      <td>ファースト・キス</td>\n",
              "      <td>番組名ファースト・キス「兄と妹の最終章！」</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['21', '21']</td>\n",
              "      <td>番組詳細成田空港で飛行機に乗ろうとしていた美緒(井上真央)の前に、和樹(伊藤英明)が現れる。...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7666</th>\n",
              "      <td>7666</td>\n",
              "      <td>0707_CX_月21</td>\n",
              "      <td>ファースト・キス</td>\n",
              "      <td>番組名ファースト・キス「天国から来た手紙」</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['21', '21']</td>\n",
              "      <td>番組詳細和樹(伊藤英明)たちと楽しい時間を過ごし、秋生(平岡祐太)と恋をして幸せを感じるよう...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7667 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ... sharp_detail_epg_tknz\n",
              "0              0  ...                   NaN\n",
              "1              1  ...                   NaN\n",
              "2              2  ...                   NaN\n",
              "3              3  ...                   NaN\n",
              "4              4  ...                   NaN\n",
              "...          ...  ...                   ...\n",
              "7662        7662  ...                   NaN\n",
              "7663        7663  ...                   NaN\n",
              "7664        7664  ...                   NaN\n",
              "7665        7665  ...                   NaN\n",
              "7666        7666  ...                   NaN\n",
              "\n",
              "[7667 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-SFrbJDgbFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def removeTrash (text):\n",
        "    import re\n",
        "\n",
        "    result_text = text\n",
        "    result_text = re.sub(r\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\", \"\", result_text)\n",
        "    result_text = re.sub(r\"番組詳細|制作・著作|制作著作\", \"\", result_text)\n",
        "    result_text = re.sub(r\"[!\\(\\)=『』～/]\", \"\", result_text)\n",
        "    result_text = re.sub(r\"フジテレビ|日本テレビ|TBS|テレビ朝日|TBS|関西テレビ\", \"\", result_text)\n",
        "    \n",
        "    result_text = re.sub(r\"【公式.*?】\", \"\", result_text)\n",
        "    result_text = re.sub(r\"\\u3000\", \"\", result_text)\n",
        "\n",
        "    return result_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvxQ1LZMh_ai",
        "colab_type": "code",
        "outputId": "f3676fdf-a0f2-4bb6-8973-822f2fec628e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "removeTrash(df['sharp_detail_epg'][20])"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'桑野阿部寛が仕事中に倒れ、中川尾美としのりの病院に運び込まれる。見舞いに訪れたまどか吉田羊、有希江稲森いずみ、早紀深川麻衣は、皮肉も全く言わず、いつになく素直で別人のような態度の桑野に大いに驚く。病気をきっかけに桑野が“いい人\"になったと喜ぶ有希江と早紀に対して、普段から桑野とケンカばかりのまどかだけは、素直なのはあくまで一時的なものに違いないと疑うが、有希江から「桑野さんに厳しすぎ」と指摘されてしまう。    案の定、まどかは回復した桑野とまたもやささいなことで言い争いに。有希江や早紀には好意的なのに、なぜ自分には皮肉ばかり言うのかー。納得がいかないまどかに対し、早紀は、男と女の間には言葉と感情が裏腹になることがあると力説。それを体現した自分の舞台を見にきてほしいと、まどかたちを誘う。数日後、都合が悪くなり、舞台に行けなくなったまどかが困っていると、偶然桑野がやって来て、自分が代わりに行くと言い出す。早紀が、桑野には来てほしくないと言っていたことを思い出したまどかは慌てるが、一度行く気になった桑野を止められず、結局、桑野と有希江が舞台を見に行くことに。まどかは2人のデート?が気になって…。阿部寛    吉田羊  深川麻衣  塚本高史  咲妃みゆ  平祐奈    阿南敦子  奈緒  荒井敦史  小野寺ずる  美音    REDRICE湘南乃風  デビット伊東  不破万作    三浦理恵子  尾美としのり  稲森いずみ  草笛光子【脚本】  尾崎将也結婚できない男アットホーム・ダッドシグナル長期未解決事件捜査班他  【演出】  三宅喜重結婚できない男パーフェクトワールド僕のヤバイ妻サイレーン刑事×彼女×完全悪女  小松隆志MMJ結婚できない男美しい隣人白い春植田尚MMJ結婚できない男サキまっすぐな男鬼嫁日記  【チーフプロデューサー】  安藤和久  東城祐司MMJ  【プロデューサー】  米田孝  伊藤達哉MMJ  木曽貴美子MMJ  【制作】    MMJメディアミックス・ジャパン詳しい情報は番組ホームページへ  「まだ結婚できない男」で検索'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIgBCGTUcorI",
        "colab_type": "code",
        "outputId": "f54eb4f4-fdee-4fef-ff77-f4ed85ff1750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "mecab = MeCab.Tagger()\n",
        "mecab.parse(\"\")\n",
        "for i, text in enumerate( df['sharp_detail_epg']):\n",
        "    text_tokenized = []\n",
        "    # print(i)\n",
        "\n",
        "    # URL、記号などのゴミを取り除く\n",
        "    if type(text) is not str: \n",
        "        if np.isnan(text) :\n",
        "            continue \n",
        "    text = removeTrash(text)\n",
        "    node = mecab.parseToNode(text)\n",
        "    while node:\n",
        "        node = node.next\n",
        "        if node is None:\n",
        "            continue\n",
        "\n",
        "        if not node.feature.startswith(\"BOS/EOS\") and not node.feature.startswith(\"助詞\") and\\\n",
        "            not node.feature.startswith(\"記号\") and\\\n",
        "            node.feature.find(\"人名\") == -1 and\\\n",
        "            not node.feature.startswith(\"助動詞\"):\n",
        "            text_tokenized.append(node.surface)\n",
        "\n",
        "    df[\"sharp_detail_epg_tknz\"].iloc[i] = text_tokenized"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdfU9gZZBRta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "a86d74cf-4095-41de-ddc6-d496a558720d"
      },
      "source": [
        "df['sharp_detail_epg_tknz'][190:220]\n",
        "#text = df['sharp_detail_epg_tknz'][190:220]\n",
        "# if type(text) is not str: \n",
        "#     if np.isnan(text) :\n",
        "#         print(\"hoge\") \n",
        "# removeTrash (df['sharp_detail_epg'][881])"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190    [菜, 津, 美, 小市, 慢太, 郎, YOU, ほか, 穂香, 拉致, さ, れ, ４,...\n",
              "191    [菜, 津, 美, 小市, 慢太, 郎, YOU, ほか, 橘, ひかり, 3, 年, 前,...\n",
              "192    [菜, 津, 美, 小市, 慢太, 郎, YOU, ほか, 襲撃, さ, れ, 消息, 絶つ...\n",
              "193    [菜, 津, 美, 小市, 慢太, 郎, YOU, 介, ほか, 病院, 息子, 真, 襲っ...\n",
              "194    [菜, 津, 美, 小市, 慢太, 郎, YOU, 介, ほか, 殺さ, れ, 妻, 3, ...\n",
              "195    [菜, 津, 美, 小市, 慢太, 郎, YOU, 介, ほか, たち, 緊急, 指令, 室...\n",
              "196    [菜, 津, 美, 小市, 慢太, 郎, YOU, 介, ほか, 出演, タイムリミット, ...\n",
              "197    [笑い, ため, 何でも, やる, 学園, 爆笑, 王, \", こと, 主人公, 右, 前,...\n",
              "198    [文化, 祭, アドリブ, 漫才, 大, 成功, さ, せ, 右, 大知, コンビ, き, ...\n",
              "199    [本気, 芸人, 目指す, 決意, 固め, 右, 大知, 漫才, 日本一, 決める, コンテ...\n",
              "200    [右, 解散, し, 漫才, コンビ, ねずみ, 花火, 姉, 交際, 知る, 十, 年, ...\n",
              "201    [右, 笑い, まっすぐ, 姿勢, 胸, 打た, れ, 自分, たち, 原点, 取り戻し, ...\n",
              "202    [漫才, 日本一, 決める, NMC, 決勝, 進出, 決め, コンビ, デジタル, きん,...\n",
              "203    [ついに, 最終, 高校, 卒業, し, 右, 一人暮らし, 始め, 大知, お笑い, 養成...\n",
              "204    [再び, 右, 大知, コンビ, 戻っ, ゃり, 暮らし, 芸人, 選抜, クラス, 芸, ...\n",
              "205    [トキワ, 自動車, 経営, 戦略, 室, 次長, 天敵, 常務, 対立, し, 府中, 工...\n",
              "206    [府中, 工場, 戦う, こと, 決意, し, 新, 監督, 候補, 探す, 中, 因縁, ...\n",
              "207    [初, 公式, 戦, 控え, 新生, アストロズ, 相撲, 部屋, 稽古, 練習, 余念, ...\n",
              "208    [戦力, 不足, 補う, ため, 救世主, なる, 選手, リクルート, する, 中, 上手...\n",
              "209    [優勝, あと, 一, 歩, アストロズ, 宿敵, サイクロンズ, 力, 差, 突きつけ, ...\n",
              "210    [宿敵, サイクロンズ, 惜しくも, 負け, 優勝, 逃し, アストロズ, 本社, 厳しい,...\n",
              "211    [本社, 天敵, 社長, 交代, 現実味, 帯び, 率いる, アストロズ, 存続, 危機, ...\n",
              "212    [カザマ, 商事, 買収, 成立, 目前, 社長, 誕生, カウントダウン, 始まる, 現,...\n",
              "213    [去年, 宿敵, サイクロンズ, 惜敗, し, アストロズ, 雪辱, 戦, なる, 2, 年...\n",
              "214    [自分, 府中, 工場, 飛ばし, の, 最も, 信頼, し, い, 上司, 禅, ついに,...\n",
              "215    [大, 歩, 恋, 樹, 井, 巳, 真, 飛, 猿, 時, 次, ノブ, 大方, 斐紗, ...\n",
              "216    [大, 歩, 恋, 樹, 井, 巳, 真, 飛, 猿, 時, 次, ノブ, 大方, 斐紗, ...\n",
              "217    [大, 歩, 恋, 樹, 井, 巳, 真, 飛, 猿, 時, 次, ノブ, 大方, 斐紗, ...\n",
              "218    [大, 歩, 恋, 樹, 井, 巳, 真, 飛, 猿, 時, 次, ノブ, 大方, 斐紗, ...\n",
              "219    [大, 歩, 恋, 樹, 井, 巳, 真, 飛, 猿, 時, 次, ノブ, 大方, 斐紗, ...\n",
              "Name: sharp_detail_epg_tknz, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkx2kGN1EaMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40452ec7-1f95-46b5-8f9d-0b109716fb9a"
      },
      "source": [
        "df[\"sharp_detail_epg_tknz\"][190]"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['菜',\n",
              " '津',\n",
              " '美',\n",
              " '小市',\n",
              " '慢太',\n",
              " '郎',\n",
              " 'YOU',\n",
              " 'ほか',\n",
              " '穂香',\n",
              " '拉致',\n",
              " 'さ',\n",
              " 'れ',\n",
              " '４',\n",
              " '時間',\n",
              " '経過',\n",
              " '希',\n",
              " '葵',\n",
              " '暴行',\n",
              " '動画',\n",
              " 'ライブ',\n",
              " '配信',\n",
              " 'する',\n",
              " '時刻',\n",
              " '迫る',\n",
              " '沖',\n",
              " 'たち',\n",
              " '強行',\n",
              " '犯',\n",
              " '係',\n",
              " '逃亡',\n",
              " 'ルート',\n",
              " 'なる',\n",
              " '港',\n",
              " '急ぐ',\n",
              " 'ら',\n",
              " '葵',\n",
              " '捜索',\n",
              " '全力',\n",
              " '注ぐ',\n",
              " '一方',\n",
              " '過去',\n",
              " '洗っ',\n",
              " 'い',\n",
              " 'その',\n",
              " '意外',\n",
              " '正体',\n",
              " '突き止める',\n",
              " 'それ',\n",
              " '聞い',\n",
              " '栞',\n",
              " '菜',\n",
              " '津',\n",
              " '美',\n",
              " '妹',\n",
              " '葵',\n",
              " 'ある',\n",
              " '廃校',\n",
              " '監禁',\n",
              " 'さ',\n",
              " 'れ',\n",
              " 'いる',\n",
              " 'はず',\n",
              " '言い',\n",
              " '出し',\n",
              " '廃校',\n",
              " '緊迫',\n",
              " '救出',\n",
              " '劇',\n",
              " '始まる',\n",
              " '演出',\n",
              " '原作',\n",
              " '\"',\n",
              " 'Based',\n",
              " 'on',\n",
              " 'the',\n",
              " 'series',\n",
              " '\"',\n",
              " 'Voice',\n",
              " '\",',\n",
              " 'produced',\n",
              " 'and',\n",
              " 'distributed',\n",
              " 'byStudio',\n",
              " 'Dragon',\n",
              " 'Corporation',\n",
              " 'and',\n",
              " 'CJ',\n",
              " 'ENM',\n",
              " 'Co',\n",
              " '.,',\n",
              " 'Ltd',\n",
              " '\"',\n",
              " '脚本',\n",
              " '主題歌',\n",
              " 'BLUE',\n",
              " 'ENCOUNT',\n",
              " 'バッドパラドックス',\n",
              " '音楽',\n",
              " '芦屋',\n",
              " 'チーフ',\n",
              " 'プロデューサー',\n",
              " 'プロデューサー',\n",
              " '制作',\n",
              " '協力',\n",
              " 'AXON',\n",
              " '製作',\n",
              " '著作']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLL1C6reD7Jj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "576de68e-b886-4b6f-8e6c-9ad2c69bcab8"
      },
      "source": [
        "df[\"sharp_detail_epg\"][190]"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'番組詳細唐沢寿明、真木よう子、増田貴久、木村祐一、石橋菜津美、田村健太郎、安井順平/小市慢太郎、YOU/菊池桃子 ほか森下葵（矢作穂香）が拉致されて４時間が経過。新田（森永悠希）が葵の暴行動画のライブ配信する時刻が迫る。沖原（木村祐一）たち強行犯係は逃亡ルートとなる港に急ぐが、樋口（唐沢寿明）らは葵の捜索に全力を注ぐ。一方、新田の過去を洗っていた緒方（田村健太郎）はその意外な正体を突き止める。それを聞いた栞（石橋菜津美）は、妹の葵がある廃校に監禁されているはずだと言い出し…。廃校で、緊迫の救出劇が始まる!!【演出】久保田充【原作】\"Based on the series \"Voice\", produced and distributed byStudio Dragon Corporation and CJ ENM Co.,Ltd\"  【脚本】浜田秀哉【主題歌】BLUE ENCOUNT「バッドパラドックス」  【音楽】ゲイリー芦屋【チーフプロデューサー】池田健司  【プロデューサー】尾上貴洋、後藤庸介  【制作協力】AXON  【製作著作】日本テレビ【公式HP】https://www.ntv.co.jp/voice/  【公式Twitter】https://twitter.com/voice_ntv  【公式Instagram】https://www.instagram.com/voice.ntv/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U2jt0o7F_b-",
        "colab_type": "code",
        "outputId": "c8e09db1-1eb6-4ed8-8963-1723d0c897f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df[\"sharp_detail_epg\"].iloc[190]"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'番組詳細唐沢寿明、真木よう子、増田貴久、木村祐一、石橋菜津美、田村健太郎、安井順平/小市慢太郎、YOU/菊池桃子 ほか森下葵（矢作穂香）が拉致されて４時間が経過。新田（森永悠希）が葵の暴行動画のライブ配信する時刻が迫る。沖原（木村祐一）たち強行犯係は逃亡ルートとなる港に急ぐが、樋口（唐沢寿明）らは葵の捜索に全力を注ぐ。一方、新田の過去を洗っていた緒方（田村健太郎）はその意外な正体を突き止める。それを聞いた栞（石橋菜津美）は、妹の葵がある廃校に監禁されているはずだと言い出し…。廃校で、緊迫の救出劇が始まる!!【演出】久保田充【原作】\"Based on the series \"Voice\", produced and distributed byStudio Dragon Corporation and CJ ENM Co.,Ltd\"  【脚本】浜田秀哉【主題歌】BLUE ENCOUNT「バッドパラドックス」  【音楽】ゲイリー芦屋【チーフプロデューサー】池田健司  【プロデューサー】尾上貴洋、後藤庸介  【制作協力】AXON  【製作著作】日本テレビ【公式HP】https://www.ntv.co.jp/voice/  【公式Twitter】https://twitter.com/voice_ntv  【公式Instagram】https://www.instagram.com/voice.ntv/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KumXpDGl9Yhl",
        "colab_type": "code",
        "outputId": "8e0847f9-2acb-47d3-e9ad-57ec9157422e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "str(df[\"sharp_detail_epg_tknz\"].iloc[190])"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[\\'菜\\', \\'津\\', \\'美\\', \\'小市\\', \\'慢太\\', \\'郎\\', \\'YOU\\', \\'ほか\\', \\'穂香\\', \\'拉致\\', \\'さ\\', \\'れ\\', \\'４\\', \\'時間\\', \\'経過\\', \\'希\\', \\'葵\\', \\'暴行\\', \\'動画\\', \\'ライブ\\', \\'配信\\', \\'する\\', \\'時刻\\', \\'迫る\\', \\'沖\\', \\'たち\\', \\'強行\\', \\'犯\\', \\'係\\', \\'逃亡\\', \\'ルート\\', \\'なる\\', \\'港\\', \\'急ぐ\\', \\'ら\\', \\'葵\\', \\'捜索\\', \\'全力\\', \\'注ぐ\\', \\'一方\\', \\'過去\\', \\'洗っ\\', \\'い\\', \\'その\\', \\'意外\\', \\'正体\\', \\'突き止める\\', \\'それ\\', \\'聞い\\', \\'栞\\', \\'菜\\', \\'津\\', \\'美\\', \\'妹\\', \\'葵\\', \\'ある\\', \\'廃校\\', \\'監禁\\', \\'さ\\', \\'れ\\', \\'いる\\', \\'はず\\', \\'言い\\', \\'出し\\', \\'廃校\\', \\'緊迫\\', \\'救出\\', \\'劇\\', \\'始まる\\', \\'演出\\', \\'原作\\', \\'\"\\', \\'Based\\', \\'on\\', \\'the\\', \\'series\\', \\'\"\\', \\'Voice\\', \\'\",\\', \\'produced\\', \\'and\\', \\'distributed\\', \\'byStudio\\', \\'Dragon\\', \\'Corporation\\', \\'and\\', \\'CJ\\', \\'ENM\\', \\'Co\\', \\'.,\\', \\'Ltd\\', \\'\"\\', \\'脚本\\', \\'主題歌\\', \\'BLUE\\', \\'ENCOUNT\\', \\'バッドパラドックス\\', \\'音楽\\', \\'芦屋\\', \\'チーフ\\', \\'プロデューサー\\', \\'プロデューサー\\', \\'制作\\', \\'協力\\', \\'AXON\\', \\'製作\\', \\'著作\\']'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZORc5o1Pco9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnokRMvd1fnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "X = vectorizer.fit_transform(\n",
        "    [str(i) for i in df[\"sharp_detail_epg_tknz\"].values]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGenqOWt1gPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "114db266-2b11-4746-d422-9c9ba9d8be45"
      },
      "source": [
        "X"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7667x30691 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 734548 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62bm14bW1gqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "004e3f29-1497-4f32-8ac0-9acc8bb76ccc"
      },
      "source": [
        "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>03</th>\n",
              "      <th>04</th>\n",
              "      <th>0406</th>\n",
              "      <th>0456666</th>\n",
              "      <th>050</th>\n",
              "      <th>07</th>\n",
              "      <th>0710</th>\n",
              "      <th>08</th>\n",
              "      <th>1</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>1014</th>\n",
              "      <th>1018</th>\n",
              "      <th>102</th>\n",
              "      <th>1024</th>\n",
              "      <th>1028</th>\n",
              "      <th>103</th>\n",
              "      <th>1030</th>\n",
              "      <th>1031</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>109</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>1100</th>\n",
              "      <th>111</th>\n",
              "      <th>1110</th>\n",
              "      <th>1111</th>\n",
              "      <th>1113</th>\n",
              "      <th>1114</th>\n",
              "      <th>1117</th>\n",
              "      <th>1118</th>\n",
              "      <th>112</th>\n",
              "      <th>1121</th>\n",
              "      <th>...</th>\n",
              "      <th>黙り込ん</th>\n",
              "      <th>黙る</th>\n",
              "      <th>黙秘</th>\n",
              "      <th>黙認</th>\n",
              "      <th>黛</th>\n",
              "      <th>鼓</th>\n",
              "      <th>鼓動</th>\n",
              "      <th>鼓笛隊</th>\n",
              "      <th>鼓舞</th>\n",
              "      <th>鼠</th>\n",
              "      <th>鼻</th>\n",
              "      <th>鼻息</th>\n",
              "      <th>鼻歌</th>\n",
              "      <th>鼻血</th>\n",
              "      <th>齋</th>\n",
              "      <th>齋籐</th>\n",
              "      <th>齢</th>\n",
              "      <th>龍</th>\n",
              "      <th>龍崎</th>\n",
              "      <th>龍門</th>\n",
              "      <th>０</th>\n",
              "      <th>１</th>\n",
              "      <th>１つ</th>\n",
              "      <th>２</th>\n",
              "      <th>３</th>\n",
              "      <th>４</th>\n",
              "      <th>５</th>\n",
              "      <th>６</th>\n",
              "      <th>７</th>\n",
              "      <th>８</th>\n",
              "      <th>９</th>\n",
              "      <th>ａｖ</th>\n",
              "      <th>ｃｍ</th>\n",
              "      <th>ｄｎａ</th>\n",
              "      <th>ｈｐ</th>\n",
              "      <th>ｍｄ</th>\n",
              "      <th>ｎｈｋ</th>\n",
              "      <th>ｏｌ</th>\n",
              "      <th>ｓｉｔ</th>\n",
              "      <th>ｓｎｓ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.033866</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.093859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7662</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7663</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7664</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7665</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7666</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7667 rows × 30691 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0   00  000   01   02   03   04  ...  ｄｎａ   ｈｐ   ｍｄ  ｎｈｋ   ｏｌ  ｓｉｔ  ｓｎｓ\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "7662  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "7663  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "7664  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "7665  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "7666  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[7667 rows x 30691 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mJ-vAUP1hDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2285423f-afa0-4f8d-c6ea-52a9e55d54e4"
      },
      "source": [
        "vectorizer.idf_"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.57751527, 8.33537319, 8.55851674, ..., 9.25166392, 9.25166392,\n",
              "       8.84619882])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sAUTzMn4s7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# idf値の確認\n",
        "\n",
        "idf = pd.Series(vectorizer.idf_, index=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ]) \\\n",
        "    .to_frame(\"idf\") \\\n",
        "    .sort_values(\"idf\", ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_nlKH7M4tTj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bd67a2e-86c5-42d2-e48a-186b5b01fb7a"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "idf.iloc[1:100]"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>山場</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サンダー</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山地</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>迎い</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サントリー</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山中湖</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サンド</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山の神</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サンバ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山々</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>屋根裏</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サヴァ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>屋板</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>屋外</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>屋号</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サーガールルズ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サンダル</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山歩き</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サーディン</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サンクス</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>岐英</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>霧氷</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>岐之</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山頂</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サルドニア</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山里</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山肌</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山積</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サワ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サワダ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サワラ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山登り</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サンエアーズ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サンエナジー</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>山波</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>屋内</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サード</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ディアシスターキャバクラ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>シェルジュスタート</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>屁理屈</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>シガー</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>局内</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>シゲオ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>尾藤</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>霊安室</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>近世</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>尽くそ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>尽く</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>霊きゅう</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>尽かさ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>シック</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>尚早</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>近付ける</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>尖端</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>シェルター</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>シェミツコ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>迎え撃と</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>霊長</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>迎賓館</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>届けろ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サーフ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サーフィン</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>近かっ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サーブ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ザキヤマ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ザザッ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ザブングル</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>屈さ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>居着い</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>居留守</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>シアター</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>居中</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>居ら</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サラッ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>岐阜</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>迂回</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>川辺</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>川田</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>川岸</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サカスステージライブ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サキエル</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>川和</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>川口</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>露見</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>嵜充</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>嵌っ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サス</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>崩御</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サタケミキオ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サダメ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>込み上げる</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>露天商</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>川越</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>川野</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>サユミ</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>辺野古</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>工芸</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ゴーギャン</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>工学部</th>\n",
              "      <td>9.251664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   idf\n",
              "山場            9.251664\n",
              "サンダー          9.251664\n",
              "山地            9.251664\n",
              "迎い            9.251664\n",
              "サントリー         9.251664\n",
              "山中湖           9.251664\n",
              "サンド           9.251664\n",
              "山の神           9.251664\n",
              "サンバ           9.251664\n",
              "山々            9.251664\n",
              "屋根裏           9.251664\n",
              "サヴァ           9.251664\n",
              "屋板            9.251664\n",
              "屋外            9.251664\n",
              "屋号            9.251664\n",
              "サーガールルズ       9.251664\n",
              "サンダル          9.251664\n",
              "山歩き           9.251664\n",
              "サーディン         9.251664\n",
              "サンクス          9.251664\n",
              "岐英            9.251664\n",
              "霧氷            9.251664\n",
              "岐之            9.251664\n",
              "山頂            9.251664\n",
              "サルドニア         9.251664\n",
              "山里            9.251664\n",
              "山肌            9.251664\n",
              "山積            9.251664\n",
              "サワ            9.251664\n",
              "サワダ           9.251664\n",
              "サワラ           9.251664\n",
              "山登り           9.251664\n",
              "サンエアーズ        9.251664\n",
              "サンエナジー        9.251664\n",
              "山波            9.251664\n",
              "屋内            9.251664\n",
              "サード           9.251664\n",
              "ディアシスターキャバクラ  9.251664\n",
              "シェルジュスタート     9.251664\n",
              "屁理屈           9.251664\n",
              "シガー           9.251664\n",
              "局内            9.251664\n",
              "シゲオ           9.251664\n",
              "尾藤            9.251664\n",
              "霊安室           9.251664\n",
              "近世            9.251664\n",
              "尽くそ           9.251664\n",
              "尽く            9.251664\n",
              "霊きゅう          9.251664\n",
              "尽かさ           9.251664\n",
              "シック           9.251664\n",
              "尚早            9.251664\n",
              "近付ける          9.251664\n",
              "尖端            9.251664\n",
              "シェルター         9.251664\n",
              "シェミツコ         9.251664\n",
              "迎え撃と          9.251664\n",
              "霊長            9.251664\n",
              "迎賓館           9.251664\n",
              "届けろ           9.251664\n",
              "サーフ           9.251664\n",
              "サーフィン         9.251664\n",
              "近かっ           9.251664\n",
              "サーブ           9.251664\n",
              "ザキヤマ          9.251664\n",
              "ザザッ           9.251664\n",
              "ザブングル         9.251664\n",
              "屈さ            9.251664\n",
              "居着い           9.251664\n",
              "居留守           9.251664\n",
              "シアター          9.251664\n",
              "居中            9.251664\n",
              "居ら            9.251664\n",
              "サラッ           9.251664\n",
              "岐阜            9.251664\n",
              "迂回            9.251664\n",
              "川辺            9.251664\n",
              "川田            9.251664\n",
              "川岸            9.251664\n",
              "サカスステージライブ    9.251664\n",
              "サキエル          9.251664\n",
              "川和            9.251664\n",
              "川口            9.251664\n",
              "露見            9.251664\n",
              "嵜充            9.251664\n",
              "嵌っ            9.251664\n",
              "サス            9.251664\n",
              "崩御            9.251664\n",
              "サタケミキオ        9.251664\n",
              "サダメ           9.251664\n",
              "込み上げる         9.251664\n",
              "露天商           9.251664\n",
              "川越            9.251664\n",
              "川野            9.251664\n",
              "サユミ           9.251664\n",
              "辺野古           9.251664\n",
              "工芸            9.251664\n",
              "ゴーギャン         9.251664\n",
              "工学部           9.251664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIR0JSNS4tsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ePCMx4Da-9I"
      },
      "source": [
        "## 形態素解析\n",
        "---\n",
        "\n",
        "MeCab を利用した形態素解析と、簡単な処理の例を示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0zHt5kiTa-9d"
      },
      "source": [
        "### 簡単な例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B_7wgWRsa-9l",
        "colab": {}
      },
      "source": [
        "# ※これは、演習用に単語文書行列を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
        "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qdvArrtWa-9o"
      },
      "source": [
        "CountVectorizer が生成する単語文書行列では、行 (横) 方向が1つの文書を表し、それぞれの列に単語の出現回数が格納されます (※単語文書行列と言った場合、列方向が文書を表す場合もあるので、他の文献を読む際は注意が必要です)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ilxvlhda-9o"
      },
      "source": [
        "どの列がどの単語と対応しているかを知るためには、vectorizer の vocabulary_ を参照します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQZkYzg_a-9p",
        "colab": {}
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-XZW_Vqa-9u"
      },
      "source": [
        "新しい文書に対しては、transform で変換します。\n",
        "\n",
        "なお、fit\\_transform の際に出てこなかった単語 (= vocabulary_ にない単語) については、行列内に登場しません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "spozm9-pa-9w",
        "colab": {}
      },
      "source": [
        "# transform も、リスト形式で与える必要があるので注意\n",
        "X_new = vectorizer.transform([\n",
        "    \"Hello I like this pen\"\n",
        "])\n",
        "X_new.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fUP0dONFa-9y"
      },
      "source": [
        "### 日本語データに適用\n",
        "前処理済みの日本語データに適用してみます。DataFrame にスペース区切りのテキストを準備している場合、DataFrame の列を参照させたものをそのまま与えることができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3XTvS-VKa-9z",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X = vectorizer.fit_transform(df[\"text_tokenized\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "syuYu8hga-91",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oVIavU0Xa-92",
        "colab": {}
      },
      "source": [
        "X[0].toarray()"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "P-6WpdMM7ywT",
    "outputId": "b05b0c44-ed2c-469c-b199-f50ec6cda48f"
   },
   "outputs": [],
   "source": [
    "# !apt install aptitude\n",
    "# !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
    "# !pip install mecab-python3==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahF2OfXfa-9B"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import MeCab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUHMMXZRa-9E"
   },
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCwAqWLba-9F",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# タブ (\\t) 区切りファイルを読み込む\n",
    "# df = pd.read_csv(\"./drive/My Drive/0_インテグ作業/data/EPG_checking (1).csv\")\n",
    "df = pd.read_excel(\"./data/EPG_checking (1).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kN9Ikeaa990W"
   },
   "outputs": [],
   "source": [
    "df[\"sharp_detail_epg_tknz\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GnkQyB7YtinW",
    "outputId": "202a697b-0e36-4b93-8164-24c51c5917e7"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drama_key</th>\n",
       "      <th>drama_title</th>\n",
       "      <th>sharp_title</th>\n",
       "      <th>sharp_num_cnt</th>\n",
       "      <th>sharp_num_epg</th>\n",
       "      <th>start_time</th>\n",
       "      <th>sharp_detail_epg</th>\n",
       "      <th>sharp_detail_epg_tknz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1910_CX_月21</td>\n",
       "      <td>シャーロック</td>\n",
       "      <td>番組名シャーロック【危険な天才探偵×スマートな医師ー今夜、運命の出逢い】　#01</td>\n",
       "      <td>1</td>\n",
       "      <td>['#01']</td>\n",
       "      <td>['21', '22']</td>\n",
       "      <td>番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1910_CX_月21</td>\n",
       "      <td>シャーロック</td>\n",
       "      <td>番組名シャーロック【探偵×医師最強バディ始動!天才VS聖女の謎解き心理戦】　#02</td>\n",
       "      <td>2</td>\n",
       "      <td>['#02']</td>\n",
       "      <td>['21', '22']</td>\n",
       "      <td>番組詳細「FIVBワールドカップバレーボール2019　男子　日本×ブラジル」延長の際、放送時...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1910_CX_月21</td>\n",
       "      <td>シャーロック</td>\n",
       "      <td>番組名シャーロック【天才VS詐欺師の騙し合い!ノンストップのどんでん返し】　#03</td>\n",
       "      <td>3</td>\n",
       "      <td>['#03']</td>\n",
       "      <td>['21', '21']</td>\n",
       "      <td>番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1910_CX_月21</td>\n",
       "      <td>シャーロック</td>\n",
       "      <td>番組名シャーロック【試合直前に消えたボクシング世界王者!オレンジの傘の謎】　#04</td>\n",
       "      <td>4</td>\n",
       "      <td>['#04']</td>\n",
       "      <td>['21', '21']</td>\n",
       "      <td>番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1910_CX_月21</td>\n",
       "      <td>シャーロック</td>\n",
       "      <td>番組名シャーロック【歩く死体の謎!熱帯魚と母の愛…その真相、正義か狂気か】　#05</td>\n",
       "      <td>5</td>\n",
       "      <td>['#05']</td>\n",
       "      <td>['21', '21']</td>\n",
       "      <td>番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>7662</td>\n",
       "      <td>0710_TBS_日21</td>\n",
       "      <td>ハタチの恋人</td>\n",
       "      <td>番組名ハタチの恋人「運命の再会」</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['21', '21']</td>\n",
       "      <td>番組詳細レストランに向かった圭祐(明石家さんま)は、かつて交際していた絵里(小泉今日子)と再...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>7663</td>\n",
       "      <td>0710_TBS_日21</td>\n",
       "      <td>ハタチの恋人</td>\n",
       "      <td>番組名ハタチの恋人「バージンロード」</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['21', '21']</td>\n",
       "      <td>番組詳細ユリ(長沢まさみ)は、由紀夫(塚本高史)の父親に会うと約束した日に、圭祐(明石家さん...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>7664</td>\n",
       "      <td>0707_CX_月21</td>\n",
       "      <td>ファースト・キス</td>\n",
       "      <td>番組名ファースト・キス</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['21', '21']</td>\n",
       "      <td>番組詳細ファースト・キス◇秋生（平岡祐太）への思いを捨て、ロサンゼルスに帰ることを決意した美...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>7665</td>\n",
       "      <td>0707_CX_月21</td>\n",
       "      <td>ファースト・キス</td>\n",
       "      <td>番組名ファースト・キス「兄と妹の最終章！」</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['21', '21']</td>\n",
       "      <td>番組詳細成田空港で飛行機に乗ろうとしていた美緒(井上真央)の前に、和樹(伊藤英明)が現れる。...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>7666</td>\n",
       "      <td>0707_CX_月21</td>\n",
       "      <td>ファースト・キス</td>\n",
       "      <td>番組名ファースト・キス「天国から来た手紙」</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['21', '21']</td>\n",
       "      <td>番組詳細和樹(伊藤英明)たちと楽しい時間を過ごし、秋生(平岡祐太)と恋をして幸せを感じるよう...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7667 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     drama_key drama_title  \\\n",
       "0              0   1910_CX_月21      シャーロック   \n",
       "1              1   1910_CX_月21      シャーロック   \n",
       "2              2   1910_CX_月21      シャーロック   \n",
       "3              3   1910_CX_月21      シャーロック   \n",
       "4              4   1910_CX_月21      シャーロック   \n",
       "...          ...           ...         ...   \n",
       "7662        7662  0710_TBS_日21      ハタチの恋人   \n",
       "7663        7663  0710_TBS_日21      ハタチの恋人   \n",
       "7664        7664   0707_CX_月21    ファースト・キス   \n",
       "7665        7665   0707_CX_月21    ファースト・キス   \n",
       "7666        7666   0707_CX_月21    ファースト・キス   \n",
       "\n",
       "                                    sharp_title  sharp_num_cnt sharp_num_epg  \\\n",
       "0      番組名シャーロック【危険な天才探偵×スマートな医師ー今夜、運命の出逢い】　#01              1       ['#01']   \n",
       "1     番組名シャーロック【探偵×医師最強バディ始動!天才VS聖女の謎解き心理戦】　#02              2       ['#02']   \n",
       "2     番組名シャーロック【天才VS詐欺師の騙し合い!ノンストップのどんでん返し】　#03              3       ['#03']   \n",
       "3     番組名シャーロック【試合直前に消えたボクシング世界王者!オレンジの傘の謎】　#04              4       ['#04']   \n",
       "4     番組名シャーロック【歩く死体の謎!熱帯魚と母の愛…その真相、正義か狂気か】　#05              5       ['#05']   \n",
       "...                                         ...            ...           ...   \n",
       "7662                           番組名ハタチの恋人「運命の再会」             14           NaN   \n",
       "7663                         番組名ハタチの恋人「バージンロード」             15           NaN   \n",
       "7664                                番組名ファースト・キス              1           NaN   \n",
       "7665                      番組名ファースト・キス「兄と妹の最終章！」              2           NaN   \n",
       "7666                      番組名ファースト・キス「天国から来た手紙」              3           NaN   \n",
       "\n",
       "        start_time                                   sharp_detail_epg  \\\n",
       "0     ['21', '22']  番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...   \n",
       "1     ['21', '22']  番組詳細「FIVBワールドカップバレーボール2019　男子　日本×ブラジル」延長の際、放送時...   \n",
       "2     ['21', '21']  番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...   \n",
       "3     ['21', '21']  番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...   \n",
       "4     ['21', '21']  番組詳細【公式HP】  https://www.fujitv.co.jp/sherlock/...   \n",
       "...            ...                                                ...   \n",
       "7662  ['21', '21']  番組詳細レストランに向かった圭祐(明石家さんま)は、かつて交際していた絵里(小泉今日子)と再...   \n",
       "7663  ['21', '21']  番組詳細ユリ(長沢まさみ)は、由紀夫(塚本高史)の父親に会うと約束した日に、圭祐(明石家さん...   \n",
       "7664  ['21', '21']  番組詳細ファースト・キス◇秋生（平岡祐太）への思いを捨て、ロサンゼルスに帰ることを決意した美...   \n",
       "7665  ['21', '21']  番組詳細成田空港で飛行機に乗ろうとしていた美緒(井上真央)の前に、和樹(伊藤英明)が現れる。...   \n",
       "7666  ['21', '21']  番組詳細和樹(伊藤英明)たちと楽しい時間を過ごし、秋生(平岡祐太)と恋をして幸せを感じるよう...   \n",
       "\n",
       "      sharp_detail_epg_tknz  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "...                     ...  \n",
       "7662                    NaN  \n",
       "7663                    NaN  \n",
       "7664                    NaN  \n",
       "7665                    NaN  \n",
       "7666                    NaN  \n",
       "\n",
       "[7667 rows x 9 columns]"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fqtfcBd6a-96",
        "colab": {}
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bnDo6uFfa-97"
      },
      "source": [
        "　"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9T8K1Sba-97"
      },
      "source": [
        "## TF-IDF変換\n",
        "---\n",
        "\n",
        "TF-IDF 変換を行うと、単語の出現回数に、他の文書全体と比較した際の希少性 (レア度) で重みを付けることができます。\n",
        "\n",
        "TF-IDF 変換済みの単語文書行列は、`TfidfVectorizer` で作成できます。"
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-SFrbJDgbFb"
   },
   "outputs": [],
   "source": [
    "def removeTrash (text):\n",
    "    import re\n",
    "\n",
    "    result_text = text\n",
    "    result_text = re.sub(r\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\", \"\", result_text)\n",
    "    result_text = re.sub(r\"番組詳細|制作・著作|制作著作\", \"\", result_text)\n",
    "    result_text = re.sub(r\"[!\\(\\)=、『』～/]\", \"\", result_text)\n",
    "    result_text = re.sub(r\"フジテレビ|日本テレビ|TBS|テレビ朝日|TBS|関西テレビ\", \"\", result_text)\n",
    "    \n",
    "    result_text = re.sub(r\"【公式.*?】\", \"\", result_text)\n",
    "    result_text = re.sub(r\"\\u3000\", \"\", result_text)\n",
    "\n",
    "    return result_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rvxQ1LZMh_ai",
    "outputId": "ad2415cd-f8e0-4f3a-fd57-aac74b2c6def"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'桑野阿部寛が仕事中に倒れ中川尾美としのりの病院に運び込まれる。見舞いに訪れたまどか吉田羊有希江稲森いずみ早紀深川麻衣は皮肉も全く言わずいつになく素直で別人のような態度の桑野に大いに驚く。病気をきっかけに桑野が“いい人\"になったと喜ぶ有希江と早紀に対して普段から桑野とケンカばかりのまどかだけは素直なのはあくまで一時的なものに違いないと疑うが有希江から「桑野さんに厳しすぎ」と指摘されてしまう。    案の定まどかは回復した桑野とまたもやささいなことで言い争いに。有希江や早紀には好意的なのになぜ自分には皮肉ばかり言うのかー。納得がいかないまどかに対し早紀は男と女の間には言葉と感情が裏腹になることがあると力説。それを体現した自分の舞台を見にきてほしいとまどかたちを誘う。数日後都合が悪くなり舞台に行けなくなったまどかが困っていると偶然桑野がやって来て自分が代わりに行くと言い出す。早紀が桑野には来てほしくないと言っていたことを思い出したまどかは慌てるが一度行く気になった桑野を止められず結局桑野と有希江が舞台を見に行くことに。まどかは2人のデート?が気になって…。阿部寛    吉田羊  深川麻衣  塚本高史  咲妃みゆ  平祐奈    阿南敦子  奈緒  荒井敦史  小野寺ずる  美音    REDRICE湘南乃風  デビット伊東  不破万作    三浦理恵子  尾美としのり  稲森いずみ  草笛光子【脚本】  尾崎将也結婚できない男アットホーム・ダッドシグナル長期未解決事件捜査班他  【演出】  三宅喜重結婚できない男パーフェクトワールド僕のヤバイ妻サイレーン刑事×彼女×完全悪女  小松隆志MMJ結婚できない男美しい隣人白い春植田尚MMJ結婚できない男サキまっすぐな男鬼嫁日記  【チーフプロデューサー】  安藤和久  東城祐司MMJ  【プロデューサー】  米田孝  伊藤達哉MMJ  木曽貴美子MMJ  【制作】    MMJメディアミックス・ジャパン詳しい情報は番組ホームページへ  「まだ結婚できない男」で検索'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeTrash(df['sharp_detail_epg'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "cIgBCGTUcorI",
    "outputId": "ddc37774-0371-42a0-8323-27ba7d4e6e73"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8f1c7d7e8440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# URL、記号などのゴミを取り除く\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremoveTrash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f3b71dd32136>\u001b[0m in \u001b[0;36mremoveTrash\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mresult_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mresult_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"番組詳細|制作・著作|制作著作\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresult_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[!\\(\\)=、『』～/]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "mecab = MeCab.Tagger()\n",
    "mecab.parse(\"\")\n",
    "for i, text in enumerate( df['sharp_detail_epg']):\n",
    "    text_tokenized = []\n",
    "\n",
    "    # URL、記号などのゴミを取り除く\n",
    "    text = removeTrash(text)\n",
    "\n",
    "    if type(text) is not str: \n",
    "        if np.isnan(text) :\n",
    "            continue \n",
    "    node = mecab.parseToNode(text)\n",
    "    while node:\n",
    "        node = node.next\n",
    "        if node is None:\n",
    "            continue\n",
    "\n",
    "        if not node.feature.startswith(\"BOS/EOS\") and not node.feature.startswith(\"助詞\") and\\\n",
    "            not node.feature.startswith(\"記号\") and\\\n",
    "            node.feature.find(\"人名\") == -1 and\\\n",
    "            not node.feature.startswith(\"助動詞\"):\n",
    "            text_tokenized.append(node.surface)\n",
    "\n",
    "    df[\"sharp_detail_epg_tknz\"].iloc[i] = text_tokenized\n",
    "#     if i > 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "7U2jt0o7F_b-",
    "outputId": "5fa81f69-0ff6-451f-98a3-94eaa41b71f1"
   },
   "outputs": [],
   "source": [
    "df[\"sharp_detail_epg\"].iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "piBBAXK-a-98",
        "colab": {}
      },
      "source": [
        "# token_pattern は、デフォルトだと1文字の単語を除外するので、除外しないように設定する\n",
        "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwkRDYC7ylW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lr3yT8tXa-9-",
        "colab": {}
      },
      "source": [
        "# スペース区切りの文書をリストで与える\n",
        "X = vectorizer.fit_transform([\n",
        "    \"This is a pen\",\n",
        "    \"I am not a pen\",\n",
        "    \"Hello\"\n",
        "])\n",
        "X.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "of0bRS66a-9_",
        "colab": {}
      },
      "source": [
        "# ※これは、演習用に単語文書行列を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
        "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "KumXpDGl9Yhl",
    "outputId": "fb924476-6a14-4aa2-ebb3-e205cea18ce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['現代',\n",
       " '日本',\n",
       " '生まれ変わっ',\n",
       " '世界一',\n",
       " '有名',\n",
       " 'バディ',\n",
       " '数々',\n",
       " '難事件',\n",
       " '謎',\n",
       " '立ち向かう',\n",
       " 'ミステリーエンタテインメント',\n",
       " '今回',\n",
       " 'テーマ',\n",
       " '地面',\n",
       " '師',\n",
       " '詐欺',\n",
       " '巨額',\n",
       " '不動産',\n",
       " '巡り',\n",
       " '詐欺',\n",
       " '師',\n",
       " '息詰まる',\n",
       " '騙し',\n",
       " '合い',\n",
       " '展開',\n",
       " 'そして',\n",
       " '殺さ',\n",
       " 'れ',\n",
       " '詐欺',\n",
       " '師',\n",
       " '残し',\n",
       " 'ダイイングメッセージ',\n",
       " '解け',\n",
       " '現場',\n",
       " '残さ',\n",
       " 'れ',\n",
       " '短',\n",
       " '短',\n",
       " '3',\n",
       " '本',\n",
       " '枝',\n",
       " '謎',\n",
       " '終わら',\n",
       " 'どんでん返し',\n",
       " '渋谷',\n",
       " '一',\n",
       " '等地',\n",
       " 'ある',\n",
       " '空き家',\n",
       " '身元',\n",
       " '不明',\n",
       " '高齢',\n",
       " '男性',\n",
       " '死体',\n",
       " '発見',\n",
       " 'さ',\n",
       " 'れ',\n",
       " 'そこ',\n",
       " '5',\n",
       " '年',\n",
       " '前',\n",
       " '巨額',\n",
       " '地面',\n",
       " '師',\n",
       " '詐欺',\n",
       " '舞台',\n",
       " 'なっ',\n",
       " '邸宅',\n",
       " '事件',\n",
       " '後',\n",
       " '詐欺',\n",
       " '被害',\n",
       " 'あっ',\n",
       " '建設',\n",
       " '会社',\n",
       " '社長',\n",
       " 'その',\n",
       " '邸宅',\n",
       " '内',\n",
       " '自殺',\n",
       " 'し',\n",
       " 'いわく付き',\n",
       " '物件',\n",
       " '空き家',\n",
       " 'まま',\n",
       " 'なっ',\n",
       " 'い',\n",
       " '捜査',\n",
       " '一',\n",
       " '課',\n",
       " '蔵',\n",
       " '介',\n",
       " '捜査',\n",
       " '依頼',\n",
       " '受け',\n",
       " 'ディーン・フジオカ',\n",
       " 'その',\n",
       " '遺体',\n",
       " 'あっ',\n",
       " '場所',\n",
       " '検分',\n",
       " 'すると',\n",
       " '遺体',\n",
       " '手元',\n",
       " '3',\n",
       " '本',\n",
       " '木',\n",
       " '枝',\n",
       " 'ある',\n",
       " 'こと',\n",
       " '気づく',\n",
       " '壁',\n",
       " 'ある',\n",
       " 'リース',\n",
       " '枝',\n",
       " '落ち',\n",
       " '言う',\n",
       " '枝',\n",
       " '折れ',\n",
       " '断面',\n",
       " '新しい',\n",
       " 'こと',\n",
       " '指摘',\n",
       " 'する',\n",
       " 'その後',\n",
       " '死体',\n",
       " '身元',\n",
       " '5',\n",
       " '年',\n",
       " '前',\n",
       " '地面',\n",
       " '師',\n",
       " '詐欺',\n",
       " 'グループ',\n",
       " '1',\n",
       " '人',\n",
       " 'こと',\n",
       " '判明',\n",
       " 'そこ',\n",
       " '捜査',\n",
       " '二',\n",
       " '課',\n",
       " '現れ',\n",
       " 'ディーン・フジオカ',\n",
       " '典',\n",
       " '蔵',\n",
       " '介',\n",
       " '他',\n",
       " '原作',\n",
       " 'シリーズ',\n",
       " '脚本',\n",
       " '昼顔',\n",
       " '平日',\n",
       " '午後',\n",
       " '3',\n",
       " '時',\n",
       " '恋人',\n",
       " 'たち',\n",
       " '白い',\n",
       " '巨塔',\n",
       " '音楽',\n",
       " '主題歌',\n",
       " 'DEANFUJIOKAShellyA',\n",
       " '-',\n",
       " 'Sketch',\n",
       " 'プロデュース',\n",
       " '大',\n",
       " 'モンテ・クリスト',\n",
       " '伯',\n",
       " 'ー',\n",
       " '華麗',\n",
       " '復讐',\n",
       " 'ーレ・ミゼラブル',\n",
       " '終わり',\n",
       " 'なき',\n",
       " '旅路',\n",
       " '演出',\n",
       " 'モンテ・クリスト',\n",
       " '伯',\n",
       " 'ー',\n",
       " '華麗',\n",
       " '復讐',\n",
       " 'ー',\n",
       " '刑事',\n",
       " 'ゆがみ',\n",
       " '介']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sharp_detail_epg_tknz\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZORc5o1Pco9a"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "WnokRMvd1fnv",
    "outputId": "3e0046fc-d5fc-42bf-dae9-f90e7c049aaf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = vectorizer.fit_transform(\n",
    "    [str(i) for i in df[\"sharp_detail_epg_tknz\"].values]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGenqOWt1gPR"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "<7667x3247 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62bm14bW1gqp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>110</th>\n",
       "      <th>12</th>\n",
       "      <th>2</th>\n",
       "      <th>20</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>...</th>\n",
       "      <th>鹿央</th>\n",
       "      <th>麻酔</th>\n",
       "      <th>黙っ</th>\n",
       "      <th>鼻</th>\n",
       "      <th>１</th>\n",
       "      <th>２</th>\n",
       "      <th>３</th>\n",
       "      <th>５</th>\n",
       "      <th>６</th>\n",
       "      <th>８</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7667 rows × 3247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1   10  100  1000       110   12         2   20  2009  2010  ...  \\\n",
       "0     0.058235  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "1     0.000000  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "2     0.049091  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "3     0.054432  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "4     0.000000  0.0  0.0   0.0  0.071025  0.0  0.105233  0.0   0.0   0.0  ...   \n",
       "...        ...  ...  ...   ...       ...  ...       ...  ...   ...   ...  ...   \n",
       "7662  0.000000  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "7663  0.000000  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "7664  0.000000  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "7665  0.000000  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "7666  0.000000  0.0  0.0   0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  ...   \n",
       "\n",
       "       鹿央   麻酔   黙っ         鼻    １    ２    ３    ５    ６    ８  \n",
       "0     0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.071025  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...       ...  ...  ...  ...  ...  ...  ...  \n",
       "7662  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7663  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7664  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7665  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7666  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[7667 rows x 3247 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4mJ-vAUP1hDw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.30575377, 9.25166392, 8.55851674, ..., 9.25166392, 9.25166392,\n",
       "       9.25166392])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sAUTzMn4s7J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_nlKH7M4tTj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIR0JSNS4tsT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ePCMx4Da-9I"
   },
   "source": [
    "## 形態素解析\n",
    "---\n",
    "\n",
    "MeCab を利用した形態素解析と、簡単な処理の例を示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYMmznRYa-9Q"
   },
   "source": [
    "### -O wakati オプション無しでの解析\n",
    "品詞を使うなど、高度な解析が必要な場合は -O wakati オプションを外し、`parseToNode` 等を用いて解析します (文字列処理に慣れたら、結果を一括で出力する `parse` を使い、文字列処理により結果を取り出すこともできます)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ImsppSXDa--C",
        "colab": {}
      },
      "source": [
        "vectorizer.idf_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7-QiVXs_a--E",
        "colab": {}
      },
      "source": [
        "# ※これは、演習用に IDF 値を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
        "pd.DataFrame(np.atleast_2d(vectorizer.idf_), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z35bpbtfa--F"
      },
      "source": [
        "デフォルトでは、各文書のノルムが1になるように正規化されています (norm=\"l2\")。確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z2Gle3k3a--G",
        "colab": {}
      },
      "source": [
        "np.linalg.norm(X.toarray(), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "HGNC4m77a-9R",
    "outputId": "12e09347-5cd3-4b59-b2ad-d92ceaecea29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EOS\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab = MeCab.Tagger()\n",
    "\n",
    "# バグ回避用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "wrgI-Vtma-9T",
    "outputId": "476b2339-036a-4fb0-e49c-40fcab9c6617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBOS/EOS,*,*,*,*,*,*,*,*\n",
      "本日\t名詞,副詞可能,*,*,*,*,本日,ホンジツ,ホンジツ\n",
      "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "晴天\t名詞,一般,*,*,*,*,晴天,セイテン,セイテン\n",
      "なり\t助動詞,*,*,*,文語・ナリ,基本形,なり,ナリ,ナリ\n",
      "\tBOS/EOS,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "source": [
    "# node が None になるまで、node.next を辿り続ける\n",
    "node = mecab.parseToNode(\"本日も晴天なり\")\n",
    "\n",
    "while node:\n",
    "    # 単語は surface、品詞は feature に格納されている\n",
    "    print(node.surface + \"\\t\" + node.feature)\n",
    "    node = node.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8ROkDtHa-9U"
   },
   "source": [
    "↑ BOS, EOS は、それぞれ文頭・文末を意味する特別な品詞です (無視できます)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "j4RzEqSXa-9V",
    "outputId": "7322dd5c-5b72-4c9b-c716-25f65db31909",
    "scrolled": true
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "くし\t名詞,一般,*,*,*,*,くし,クシ,クシ\n",
      "型\t名詞,接尾,一般,*,*,*,型,ガタ,ガタ\n",
      "関数\t名詞,一般,*,*,*,*,関数,カンスウ,カンスー\n",
      "くし\t名詞,一般,*,*,*,*,くし,クシ,クシ\n",
      "型\t名詞,接尾,一般,*,*,*,型,ガタ,ガタ\n",
      "関数\t名詞,一般,*,*,*,*,関数,カンスウ,カンスー\n",
      "（\t記号,括弧開,*,*,*,*,（,（,（\n",
      "くし\t名詞,一般,*,*,*,*,くし,クシ,クシ\n",
      "たかん\t動詞,自立,*,*,五段・ラ行,体言接続特殊,たかる,タカン,タカン\n",
      "すう\t動詞,自立,*,*,五段・ワ行促音便,基本形,すう,スウ,スウ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "）\t記号,括弧閉,*,*,*,*,）,）,）\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "デルタ\t名詞,一般,*,*,*,*,デルタ,デルタ,デルタ\n",
      "関数\t名詞,一般,*,*,*,*,関数,カンスウ,カンスー\n",
      "一定\t名詞,サ変接続,*,*,*,*,一定,イッテイ,イッテイ\n",
      "間隔\t名詞,一般,*,*,*,*,間隔,カンカク,カンカク\n",
      "並べ\t動詞,自立,*,*,一段,連用形,並べる,ナラベ,ナラベ\n",
      "超\t接頭詞,名詞接続,*,*,*,*,超,チョウ,チョー\n",
      "関数\t名詞,一般,*,*,*,*,関数,カンスウ,カンスー\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "英語\t名詞,一般,*,*,*,*,英語,エイゴ,エイゴ\n",
      "コム\t名詞,固有名詞,組織,*,*,*,コム,コム,コム\n",
      "関数\t名詞,一般,*,*,*,*,関数,カンスウ,カンスー\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "概\t名詞,サ変接続,*,*,*,*,概,ガイ,ガイ\n",
      "形\t名詞,接尾,一般,*,*,*,形,ガタ,ガタ\n",
      "キリル\t名詞,一般,*,*,*,*,*\n",
      "文字\t名詞,一般,*,*,*,*,文字,モジ,モジ\n",
      "「\t記号,括弧開,*,*,*,*,「,「,「\n",
      "Ш\t名詞,固有名詞,組織,*,*,*,*\n",
      "」\t記号,括弧閉,*,*,*,*,」,」,」\n",
      "たとえ\t動詞,自立,*,*,一段,連用形,たとえる,タトエ,タトエ\n",
      "シャー\t名詞,固有名詞,人名,一般,*,*,シャー,シャー,シャー\n",
      "関数\t名詞,一般,*,*,*,*,関数,カンスウ,カンスー\n",
      "（\t記号,括弧開,*,*,*,*,（,（,（\n",
      "しゃ\t動詞,接尾,*,*,五段・サ行,仮定縮約１,す,シャ,シャ\n",
      "ー\t名詞,一般,*,*,*,*,*\n",
      "かんす\t動詞,自立,*,*,サ変・−スル,文語基本形,かんする,カンス,カンス\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "）\t記号,括弧閉,*,*,*,*,）,）,）\n",
      "呼ば\t動詞,自立,*,*,五段・バ行,未然形,呼ぶ,ヨバ,ヨバ\n",
      "れる\t動詞,接尾,*,*,一段,基本形,れる,レル,レル\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "また\t副詞,助詞類接続,*,*,*,*,また,マタ,マタ\n",
      "わかり\t動詞,自立,*,*,五段・ラ行,連用形,わかる,ワカリ,ワカリ\n",
      "やすく\t形容詞,非自立,*,*,形容詞・アウオ段,連用テ接続,やすい,ヤスク,ヤスク\n",
      "周期\t名詞,一般,*,*,*,*,周期,シュウキ,シューキ\n",
      "的\t名詞,接尾,形容動詞語幹,*,*,*,的,テキ,テキ\n",
      "デルタ\t名詞,一般,*,*,*,*,デルタ,デルタ,デルタ\n",
      "関数\t名詞,一般,*,*,*,*,関数,カンスウ,カンスー\n",
      "呼ば\t動詞,自立,*,*,五段・バ行,未然形,呼ぶ,ヨバ,ヨバ\n",
      "れる\t動詞,接尾,*,*,一段,基本形,れる,レル,レル\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "連続\t名詞,サ変接続,*,*,*,*,連続,レンゾク,レンゾク\n",
      "関数\t名詞,一般,*,*,*,*,関数,カンスウ,カンスー\n",
      "積\t名詞,一般,*,*,*,*,積,セキ,セキ\n",
      "取る\t動詞,自立,*,*,五段・ラ行,基本形,取る,トル,トル\n",
      "こと\t名詞,非自立,一般,*,*,*,こと,コト,コト\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "一定\t名詞,サ変接続,*,*,*,*,一定,イッテイ,イッテイ\n",
      "間隔\t名詞,一般,*,*,*,*,間隔,カンカク,カンカク\n",
      "離散\t名詞,サ変接続,*,*,*,*,離散,リサン,リサン\n",
      "化\t名詞,接尾,サ変接続,*,*,*,化,カ,カ\n",
      "（\t記号,括弧開,*,*,*,*,（,（,（\n",
      "サンプリング\t名詞,サ変接続,*,*,*,*,サンプリング,サンプリング,サンプリング\n",
      "）\t記号,括弧閉,*,*,*,*,）,）,）\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "数値\t名詞,一般,*,*,*,*,数値,スウチ,スーチ\n",
      "列\t名詞,一般,*,*,*,*,列,レツ,レツ\n",
      "得る\t動詞,自立,*,*,一段,基本形,得る,エル,エル\n",
      "こと\t名詞,非自立,一般,*,*,*,こと,コト,コト\n",
      "できる\t動詞,自立,*,*,一段,基本形,できる,デキル,デキル\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "この\t連体詞,*,*,*,*,*,この,コノ,コノ\n",
      "ため\t名詞,非自立,副詞可能,*,*,*,ため,タメ,タメ\n",
      "理想\t名詞,一般,*,*,*,*,理想,リソウ,リソー\n",
      "的\t名詞,接尾,形容動詞語幹,*,*,*,的,テキ,テキ\n",
      "サンプラー\t名詞,一般,*,*,*,*,*\n",
      "モデル\t名詞,一般,*,*,*,*,モデル,モデル,モデル\n",
      "扱わ\t動詞,自立,*,*,五段・ワ行促音便,未然形,扱う,アツカワ,アツカワ\n",
      "れる\t動詞,接尾,*,*,一段,基本形,れる,レル,レル\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "成り立つ\t動詞,自立,*,*,五段・タ行,基本形,成り立つ,ナリタツ,ナリタツ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n"
     ]
    }
   ],
   "source": [
    "# BOS/EOS, 助詞, 助動詞を除外する例\n",
    "node = mecab.parseToNode(df.text.iloc[0])\n",
    "while node:\n",
    "    if not node.feature.startswith(\"BOS/EOS\") and not node.feature.startswith(\"助詞\") and not node.feature.startswith(\"助動詞\"):\n",
    "        print(node.surface + \"\\t\" + node.feature)\n",
    "    node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OboegEwa-9W"
   },
   "outputs": [],
   "source": [
    "mecab = MeCab.Tagger(\"-O wakati\")\n",
    "\n",
    "text_tokenized = []\n",
    "for text in df['text']:\n",
    "    text_tokenized.append(mecab.parse(text))\n",
    "    \n",
    "df['text_tokenized'] = text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Gjv8iS7fa-9Y",
    "outputId": "cd972b7b-0a7e-474b-d921-f9796634987b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'くし 型 関数 くし 型 関数 （ くし が たかん すう 、 ） は 、 デルタ 関数 を 一定 の 間隔 で 並べ た 超 関数 。 英語 から コム 関数 とも 。 概 形 を キリル 文字 の 「 Ш 」 に たとえ て シャー 関数 （ しゃ ー かんす う 、 ） と も 呼ば れる 。 また わかり やすく 周期 的 デルタ 関数 と も 呼ば れる 。 連続 関数 と の 積 を 取る こと により 、 一定 間隔 で 離散 化 （ サンプリング ） し た 数値 列 を 得る こと が できる 。 この ため 理想 的 な サンプラー の モデル として も 扱わ れる 。 が 成り立つ 。 \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVLcwm875xd4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD6sJOAN5w35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "colab_type": "code",
    "id": "VRf30KbQa-9a",
    "outputId": "8e183053-1f7f-4e18-fca4-4b90ac68fa2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>くし型関数 くし型関数（くしがたかんすう、）は、デルタ関数を一定の間隔で並べた超関数。英語か...</td>\n",
       "      <td>くし 型 関数 くし 型 関数 （ くし が たかん すう 、 ） は 、 デルタ 関数 を...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>フィッティングの補題 数学において、の補題 (FITTING LEMMA) は、\"M\" が直...</td>\n",
       "      <td>フィッティング の 補題 数学 において 、 の 補題 ( FITTING LEMMA ) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>理性 理性（りせい、→→→）とは、人間に本来的に備わっているとされる知的能力の一つである。言...</td>\n",
       "      <td>理性 理性 （ り せい 、 → → → ） と は 、 人間 に 本来 的 に 備わっ て...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>位相線型環 数学の函数解析学における位相線型環（いそうせんけいかん、; 位相多元環、位相代数...</td>\n",
       "      <td>位相 線型 環 数学 の 函数 解析 学 における 位相 線型 環 （ い そう せん けい...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>調和解析 数学の一分野としての調和解析（ちょうわかいせき、）は、関数や信号を基本波の重ね合わ...</td>\n",
       "      <td>調和 解析 数学 の 一 分野 として の 調和 解析 （ ちょう わかい せき 、 ） は...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>射影線型群 数学における射影線型群（しゃえいせんけいぐん、）あるいは射影一般線型群（しゃえい...</td>\n",
       "      <td>射影 線型 群 数学 における 射影 線型 群 （ し ゃえいせんけいぐん 、 ） あるいは...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>円柱 (数学) 数学において円柱（えんちゅう、）とは二次曲面（三次元空間内の曲面）の一種で、...</td>\n",
       "      <td>円柱 ( 数学 ) 数学 において 円柱 （ えん ち ゅう 、 ） と は 二 次 曲面 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>エルミート作用素 エルミート作用素（エルミートさようそ、\"HERMITIAN OPERATO...</td>\n",
       "      <td>エルミート 作用素 エルミート 作用素 （ エルミート さ よう そ 、 \" HERMITI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>パスカルの賭け パスカルの賭け（パスカルのかけ、, ）は、フランスの哲学者ブレーズ・パスカル...</td>\n",
       "      <td>パスカル の 賭け パスカル の 賭け （ パスカル の かけ 、 , ） は 、 フランス...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>ハーディ＝リトルウッドの極大函数 数学において、ハーディ＝リトルウッドの極大函数（ハーディ＝...</td>\n",
       "      <td>ハーディ ＝ リトル ウッド の 極大 函数 数学 において 、 ハーディ ＝ リトル ウッ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  ...                                     text_tokenized\n",
       "0    mathematics  ...  くし 型 関数 くし 型 関数 （ くし が たかん すう 、 ） は 、 デルタ 関数 を...\n",
       "1    mathematics  ...  フィッティング の 補題 数学 において 、 の 補題 ( FITTING LEMMA ) ...\n",
       "2     philosophy  ...  理性 理性 （ り せい 、 → → → ） と は 、 人間 に 本来 的 に 備わっ て...\n",
       "3    mathematics  ...  位相 線型 環 数学 の 函数 解析 学 における 位相 線型 環 （ い そう せん けい...\n",
       "4    mathematics  ...  調和 解析 数学 の 一 分野 として の 調和 解析 （ ちょう わかい せき 、 ） は...\n",
       "..           ...  ...                                                ...\n",
       "995  mathematics  ...  射影 線型 群 数学 における 射影 線型 群 （ し ゃえいせんけいぐん 、 ） あるいは...\n",
       "996  mathematics  ...  円柱 ( 数学 ) 数学 において 円柱 （ えん ち ゅう 、 ） と は 二 次 曲面 ...\n",
       "997  mathematics  ...  エルミート 作用素 エルミート 作用素 （ エルミート さ よう そ 、 \" HERMITI...\n",
       "998   philosophy  ...  パスカル の 賭け パスカル の 賭け （ パスカル の かけ 、 , ） は 、 フランス...\n",
       "999  mathematics  ...  ハーディ ＝ リトル ウッド の 極大 函数 数学 において 、 ハーディ ＝ リトル ウッ...\n",
       "\n",
       "[1000 rows x 3 columns]"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yB3krCe_a--L",
        "colab": {}
      },
      "source": [
        "X[0].toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exlfUKQYa--M"
      },
      "source": [
        "IDF 値の大きい単語・小さい単語を確認してみましょう。"
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6u3u4q6La-9c"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8Zsuq8qa-9c"
   },
   "source": [
    "## 単語文書行列の作成\n",
    "---\n",
    "単語文書行列は、`CountVectorizer` を用いることで作成できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zHt5kiTa-9d"
   },
   "source": [
    "### 簡単な例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyu1v9H2a-9d"
   },
   "outputs": [],
   "source": [
    "# token_pattern は、デフォルトだと1文字の単語を除外するので、除外しないように設定する\n",
    "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAiBw8v8a-9f"
   },
   "outputs": [],
   "source": [
    "# スペース区切りの文書をリストで与える\n",
    "X = vectorizer.fit_transform([\n",
    "    \"This is a pen\",\n",
    "    \"I am not a pen\",\n",
    "    \"Hello\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "9bv0sFfna-9h",
    "outputId": "82474bbc-9f04-4e0f-8be8-50276c2bffd1"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7SYAjaLOa--N",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# ※これは、演習用に IDF 値を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
        "pd.Series(vectorizer.idf_, index=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ]) \\\n",
        "    .to_frame(\"idf\") \\\n",
        "    .sort_values(\"idf\", ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AkVS36Cja--O"
      },
      "source": [
        " "
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gps06ps_a-9j"
   },
   "source": [
    "単語文書行列は、`scipy.sparse` の SparseMatrix (疎行列) の形で帰ります。疎行列形式は、単語文書行列のように疎なデータ (行列内の多くの値が 0) に対し、メモリ効率良く格納できると言う利点を持ちます。\n",
    "\n",
    "デバッグ用途等で密行列に変換したい場合は、toarray() を呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "EEus63WOa-9j",
    "outputId": "3e8ea55b-5fae-4fad-dd9c-43a697b9fe27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "B_7wgWRsa-9l",
    "outputId": "bce08bcb-9971-4981-e28d-ce4373c38239"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>am</th>\n",
       "      <th>hello</th>\n",
       "      <th>i</th>\n",
       "      <th>is</th>\n",
       "      <th>not</th>\n",
       "      <th>pen</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  am  hello  i  is  not  pen  this\n",
       "0  1   0      0  0   1    0    1     1\n",
       "1  1   1      0  1   0    1    1     0\n",
       "2  0   0      1  0   0    0    0     0"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JVGT1gv4a--P",
        "colab": {}
      },
      "source": [
        "# テストデータ\n",
        "df_test = pd.read_csv(\"dataset/wikipedia-test.txt\", sep=\"\\t\")\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JIAl91qja--Q"
      },
      "source": [
        "### 単語文書行列 (TF-IDF 適用済み) の作成\n",
        "単語文章行列を作成する前に、まずは文章を形態素解析します。"
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ※これは、演習用に単語文書行列を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
    "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdvArrtWa-9o"
   },
   "source": [
    "CountVectorizer が生成する単語文書行列では、行 (横) 方向が1つの文書を表し、それぞれの列に単語の出現回数が格納されます (※単語文書行列と言った場合、列方向が文書を表す場合もあるので、他の文献を読む際は注意が必要です)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ilxvlhda-9o"
   },
   "source": [
    "どの列がどの単語と対応しているかを知るためには、vectorizer の vocabulary_ を参照します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UQZkYzg_a-9p",
    "outputId": "a988cdd2-930f-4726-843a-b732f5aa756c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'am': 1, 'hello': 2, 'i': 3, 'is': 4, 'not': 5, 'pen': 6, 'this': 7}"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-XZW_Vqa-9u"
   },
   "source": [
    "新しい文書に対しては、transform で変換します。\n",
    "\n",
    "なお、fit\\_transform の際に出てこなかった単語 (= vocabulary_ にない単語) については、行列内に登場しません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "spozm9-pa-9w",
    "outputId": "98d444f9-12c9-4da4-f449-a4b5b272e0d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform も、リスト形式で与える必要があるので注意\n",
    "X_new = vectorizer.transform([\n",
    "    \"Hello I like this pen\"\n",
    "])\n",
    "X_new.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUP0dONFa-9y"
   },
   "source": [
    "### 日本語データに適用\n",
    "前処理済みの日本語データに適用してみます。DataFrame にスペース区切りのテキストを準備している場合、DataFrame の列を参照させたものをそのまま与えることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XTvS-VKa-9z"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X = vectorizer.fit_transform(df[\"text_tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "syuYu8hga-91",
    "outputId": "f2f053a3-7db0-4bc4-d160-6f75eb7746ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x30875 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 227179 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "oVIavU0Xa-92",
    "outputId": "00ba7571-e275-4b10-e54d-32855ddaf09d"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dvNzlApVa-95"
   },
   "source": [
    "↑この規模の単語文書行列になると、行列のサイズ (文書数x単語数) と比較し、値が入っている場所をほとんど無いことが分かります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cTmFq6lma--d",
        "colab": {}
      },
      "source": [
        "clf_lr = LogisticRegression(n_jobs=-1)\n",
        "clf_lr.fit(X, df[\"category\"])"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "fqtfcBd6a-96",
    "outputId": "76e943b3-bb82-432f-bc58-eea602970d82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'くし': 6144,\n",
       " '型': 18802,\n",
       " '関数': 30013,\n",
       " 'が': 6073,\n",
       " 'たかん': 6613,\n",
       " 'すう': 6449,\n",
       " 'は': 7144,\n",
       " 'デルタ': 11461,\n",
       " 'を': 7843,\n",
       " '一定': 14905,\n",
       " 'の': 7116,\n",
       " '間隔': 29996,\n",
       " 'で': 6838,\n",
       " '並べ': 15334,\n",
       " 'た': 6594,\n",
       " '超': 28848,\n",
       " '英語': 27409,\n",
       " 'から': 6053,\n",
       " 'コム': 9836,\n",
       " 'とも': 6910,\n",
       " '概': 23519,\n",
       " '形': 20825,\n",
       " 'キリル': 9357,\n",
       " '文字': 22466,\n",
       " 'ш': 5583,\n",
       " 'に': 7056,\n",
       " 'たとえ': 6650,\n",
       " 'て': 6823,\n",
       " 'シャー': 10264,\n",
       " 'しゃ': 6402,\n",
       " 'ー': 14873,\n",
       " 'かんす': 6067,\n",
       " 'う': 5825,\n",
       " 'と': 6857,\n",
       " 'も': 7506,\n",
       " '呼ば': 18361,\n",
       " 'れる': 7803,\n",
       " 'また': 7397,\n",
       " 'わかり': 7819,\n",
       " 'やすく': 7590,\n",
       " '周期': 18345,\n",
       " '的': 25447,\n",
       " '連続': 29323,\n",
       " '積': 26104,\n",
       " '取る': 17934,\n",
       " 'こと': 6253,\n",
       " 'により': 7084,\n",
       " '離散': 30265,\n",
       " '化': 17502,\n",
       " 'サンプリング': 10106,\n",
       " 'し': 6355,\n",
       " '数値': 22415,\n",
       " '列': 17088,\n",
       " '得る': 20972,\n",
       " 'できる': 6844,\n",
       " 'この': 6262,\n",
       " 'ため': 6668,\n",
       " '理想': 25055,\n",
       " 'な': 6973,\n",
       " 'サンプラー': 10105,\n",
       " 'モデル': 13912,\n",
       " 'として': 6884,\n",
       " '扱わ': 21703,\n",
       " '成り立つ': 21501,\n",
       " 'フィッティング': 12522,\n",
       " '補題': 27791,\n",
       " '数学': 22421,\n",
       " 'において': 7060,\n",
       " 'fitting': 2581,\n",
       " 'lemma': 3436,\n",
       " 'm': 3558,\n",
       " '直': 25531,\n",
       " '既': 22639,\n",
       " '約': 26442,\n",
       " '加': 17342,\n",
       " '群': 26891,\n",
       " '長': 29871,\n",
       " 'さ': 6295,\n",
       " '有限': 23075,\n",
       " 'あれ': 5712,\n",
       " 'ば': 7207,\n",
       " 'すべて': 6475,\n",
       " '自己': 27220,\n",
       " '準': 24515,\n",
       " '同型': 18185,\n",
       " '全': 16644,\n",
       " '単': 17633,\n",
       " '射': 19962,\n",
       " 'ある': 5708,\n",
       " 'かさ': 6012,\n",
       " 'なく': 6998,\n",
       " '冪': 16889,\n",
       " '零': 30290,\n",
       " 'という': 6860,\n",
       " '代数': 15855,\n",
       " '学': 19547,\n",
       " '定理': 19701,\n",
       " '環': 25075,\n",
       " '局所': 20115,\n",
       " '従う': 20953,\n",
       " 'なら': 7032,\n",
       " 'formula': 2607,\n",
       " '_': 1223,\n",
       " '1': 36,\n",
       " 'について': 7074,\n",
       " '仮定': 15888,\n",
       " 'より': 7765,\n",
       " '2': 690,\n",
       " '等式': 26290,\n",
       " 'それぞれ': 6571,\n",
       " '3': 804,\n",
       " '理性': 25054,\n",
       " 'り': 7785,\n",
       " 'せい': 6499,\n",
       " '人間': 15735,\n",
       " '本来': 23178,\n",
       " '備わっ': 16425,\n",
       " 'いる': 5810,\n",
       " '知的': 25736,\n",
       " '能力': 27103,\n",
       " '一つ': 14876,\n",
       " '言い換えれ': 28125,\n",
       " '推論': 22092,\n",
       " 'reasoning': 4442,\n",
       " '世界': 15295,\n",
       " 'とき': 6874,\n",
       " '意味': 21349,\n",
       " '統べる': 26640,\n",
       " '原理': 17736,\n",
       " '知性': 25733,\n",
       " '区別': 17542,\n",
       " 'ギリシア': 9412,\n",
       " '哲学': 18439,\n",
       " 'における': 7061,\n",
       " 'ヌース': 11794,\n",
       " '知': 25708,\n",
       " '叡智': 17994,\n",
       " 'ディアノイア': 11350,\n",
       " 'dia': 2209,\n",
       " '経由': 26584,\n",
       " 'noia': 3909,\n",
       " '間接': 29989,\n",
       " '基本': 18856,\n",
       " '由来': 25201,\n",
       " 'する': 6483,\n",
       " '古典': 18012,\n",
       " '語': 28361,\n",
       " '論理': 28502,\n",
       " '表す': 27694,\n",
       " 'ともに': 6918,\n",
       " 'ロゴス': 14612,\n",
       " 'あっ': 5661,\n",
       " '元来': 16505,\n",
       " '比': 23893,\n",
       " 'や': 7578,\n",
       " '割合': 17289,\n",
       " '有し': 23033,\n",
       " 'い': 5720,\n",
       " 'そこ': 6544,\n",
       " 'ラテン語': 14167,\n",
       " '同じ': 18172,\n",
       " '持つ': 21892,\n",
       " '日常': 22656,\n",
       " 'ratio': 4425,\n",
       " '訳語': 28231,\n",
       " 'れ': 7798,\n",
       " 'ロマンス': 14662,\n",
       " 'その': 6554,\n",
       " '流れ': 24238,\n",
       " '引き継い': 20692,\n",
       " 'だ': 6683,\n",
       " 'セネカ': 10877,\n",
       " 'よれ': 7768,\n",
       " 'これ': 6272,\n",
       " 'キケロ': 9311,\n",
       " 'による': 7085,\n",
       " 'いう': 5725,\n",
       " 'こうした': 6221,\n",
       " '西欧': 27840,\n",
       " '伝統': 15972,\n",
       " '類比': 30541,\n",
       " '方法': 22606,\n",
       " '秩序': 26034,\n",
       " '考える': 26954,\n",
       " '傾向': 16449,\n",
       " 'もたらし': 7523,\n",
       " '比例': 23900,\n",
       " '理解': 25063,\n",
       " '時': 22798,\n",
       " '一番': 14951,\n",
       " '典型': 16783,\n",
       " '三角': 15047,\n",
       " '測量': 24472,\n",
       " '特定': 24883,\n",
       " '時刻': 22809,\n",
       " '影': 20855,\n",
       " '棒': 23442,\n",
       " '関係': 30005,\n",
       " '直接': 25554,\n",
       " '計れ': 28162,\n",
       " 'ない': 6974,\n",
       " 'ピラミッド': 12453,\n",
       " '高': 30692,\n",
       " '基': 18844,\n",
       " 'よう': 7743,\n",
       " '場合': 18902,\n",
       " '現代': 25024,\n",
       " '英': 27393,\n",
       " '米': 26375,\n",
       " '圏': 18713,\n",
       " '分析': 17024,\n",
       " 'しばしば': 6388,\n",
       " '見': 27881,\n",
       " 'られる': 7783,\n",
       " '悟性': 21261,\n",
       " '狭義': 24953,\n",
       " '混同': 24382,\n",
       " '用法': 25186,\n",
       " '広義': 20546,\n",
       " '使わ': 16155,\n",
       " 'スコラ哲学': 10634,\n",
       " '以来': 15881,\n",
       " '西洋': 27841,\n",
       " '論証': 28506,\n",
       " '対象': 19939,\n",
       " '把握': 21720,\n",
       " 'understanding': 5256,\n",
       " '普通': 22837,\n",
       " '明晰': 22748,\n",
       " '性': 21185,\n",
       " '妥当': 19443,\n",
       " '前者': 17233,\n",
       " '直観': 25564,\n",
       " '後者': 20936,\n",
       " '属する': 20150,\n",
       " 'ショーペンハウアー': 10370,\n",
       " 'よる': 7767,\n",
       " '抽象': 21820,\n",
       " '認識': 28344,\n",
       " '概念': 23522,\n",
       " '扱う': 21699,\n",
       " 'あり': 5700,\n",
       " 'それ': 6569,\n",
       " '以上': 15875,\n",
       " 'でも': 6853,\n",
       " '以下': 15876,\n",
       " '知覚': 25741,\n",
       " 'つまり': 6802,\n",
       " '視聴覚': 28013,\n",
       " '触覚': 28115,\n",
       " '現れ': 25020,\n",
       " '感覚': 21412,\n",
       " '脳': 27137,\n",
       " 'によって': 7083,\n",
       " '時間': 22821,\n",
       " '空間': 26148,\n",
       " '因果': 18621,\n",
       " '形式': 20833,\n",
       " 'もっ': 7531,\n",
       " '現象': 25038,\n",
       " '客観': 19774,\n",
       " '要素': 27866,\n",
       " '抽出': 21819,\n",
       " '同士': 18186,\n",
       " '組み合わせ': 26553,\n",
       " '思考': 21169,\n",
       " '行う': 27637,\n",
       " '簡単': 26361,\n",
       " '言え': 28139,\n",
       " '文章': 22491,\n",
       " '読み書き': 28425,\n",
       " '活動': 24222,\n",
       " '全て': 16647,\n",
       " '頭': 30485,\n",
       " 'なか': 6985,\n",
       " '作業': 16125,\n",
       " '行わ': 27656,\n",
       " 'しかし': 6358,\n",
       " '結局': 26611,\n",
       " '表れる': 27698,\n",
       " '直接的': 25555,\n",
       " 'いわば': 5819,\n",
       " '水源': 23981,\n",
       " '汲ん': 24037,\n",
       " 'き': 6088,\n",
       " 'もの': 7551,\n",
       " '常に': 20397,\n",
       " '対応': 19915,\n",
       " 'なけれ': 7005,\n",
       " '机上': 23203,\n",
       " '空論': 26145,\n",
       " '無意味': 24707,\n",
       " 'ゆえに': 7669,\n",
       " '単に': 17635,\n",
       " '反省': 17837,\n",
       " 'reflection': 4464,\n",
       " '彼': 20877,\n",
       " '無能': 24737,\n",
       " '教授': 22366,\n",
       " '達': 29454,\n",
       " '言う': 28137,\n",
       " '自体': 27198,\n",
       " '超越': 28856,\n",
       " '存在': 19526,\n",
       " '神': 25906,\n",
       " '予感': 15537,\n",
       " '偉大': 16362,\n",
       " '持た': 21873,\n",
       " 'ず': 6488,\n",
       " 'のみ': 7138,\n",
       " '以外': 15879,\n",
       " '動物': 17438,\n",
       " '現在': 25026,\n",
       " '目': 25497,\n",
       " '前': 17206,\n",
       " '行動': 27660,\n",
       " '限定': 30084,\n",
       " 'ツバメ': 11249,\n",
       " '営巣': 18533,\n",
       " 'クモの巣': 9465,\n",
       " '作る': 16111,\n",
       " '一見': 14974,\n",
       " '基い': 18845,\n",
       " 'か': 5967,\n",
       " '見える': 27888,\n",
       " '本能': 23188,\n",
       " '発生': 25401,\n",
       " '点': 24658,\n",
       " '我々': 21525,\n",
       " '子': 19500,\n",
       " '作り': 16099,\n",
       " '相手': 25592,\n",
       " '選ぶ': 29537,\n",
       " '際': 30171,\n",
       " '説明': 28409,\n",
       " '関わり': 30002,\n",
       " '無い': 24673,\n",
       " '健康': 16391,\n",
       " '優良': 16494,\n",
       " '子孫': 19505,\n",
       " '残せる': 23836,\n",
       " '無意識': 24708,\n",
       " '大': 19118,\n",
       " '部分': 29610,\n",
       " '動かさ': 17423,\n",
       " '一方': 14928,\n",
       " '計画': 28166,\n",
       " '出来る': 16969,\n",
       " 'とらわれ': 6922,\n",
       " '未来': 23139,\n",
       " '過去': 29418,\n",
       " 'といった': 6862,\n",
       " '表象': 27715,\n",
       " '属し': 20148,\n",
       " 'すぎ': 6454,\n",
       " '考慮': 26965,\n",
       " '入れる': 16612,\n",
       " '刑法': 17086,\n",
       " 'など': 7022,\n",
       " '法': 24125,\n",
       " '罰則': 26855,\n",
       " '効果': 17407,\n",
       " '持ち': 21874,\n",
       " 'える': 5878,\n",
       " '情動': 21314,\n",
       " '動機': 17437,\n",
       " '比較': 23905,\n",
       " '衡量': 27687,\n",
       " '結果': 26615,\n",
       " '行為': 27665,\n",
       " '選択': 29548,\n",
       " '可能': 18051,\n",
       " '刑罰': 17087,\n",
       " '期待': 23110,\n",
       " '作ら': 16098,\n",
       " '断じて': 22525,\n",
       " '報復': 18896,\n",
       " '感情': 21407,\n",
       " '満たす': 24496,\n",
       " '罪人': 26833,\n",
       " '道徳': 29444,\n",
       " '矯正': 25764,\n",
       " '不可能': 15193,\n",
       " '目的': 25513,\n",
       " 'そして': 6547,\n",
       " 'カント': 9209,\n",
       " '主張': 15447,\n",
       " '法則': 24132,\n",
       " '指定': 21906,\n",
       " '実践': 19767,\n",
       " '全く': 16646,\n",
       " '否定': 18297,\n",
       " '経験': 26589,\n",
       " '高尚': 30715,\n",
       " '明らか': 22742,\n",
       " '大抵': 19179,\n",
       " '他者': 15806,\n",
       " '受ける': 17952,\n",
       " 'へ': 7321,\n",
       " '恐怖': 21215,\n",
       " '恐れ': 21211,\n",
       " '渋々': 24417,\n",
       " '自ら': 27193,\n",
       " '欲求': 23670,\n",
       " '抑え': 21722,\n",
       " '実際': 19768,\n",
       " '憂慮': 21449,\n",
       " 'そう': 6532,\n",
       " '寄与': 19841,\n",
       " 'むしろ': 7476,\n",
       " '使い方': 16147,\n",
       " '如何': 19427,\n",
       " '例えば': 16165,\n",
       " '大量': 19239,\n",
       " '虐殺': 27587,\n",
       " '極めて': 23493,\n",
       " '大きな': 19126,\n",
       " '悪': 21275,\n",
       " '実行': 19763,\n",
       " '歴史': 23802,\n",
       " '例': 16163,\n",
       " '実証': 19765,\n",
       " '論外': 28494,\n",
       " '最も': 22977,\n",
       " '野蛮': 29748,\n",
       " '宗教': 19662,\n",
       " 'ユダヤ': 14025,\n",
       " '教': 22343,\n",
       " '教義': 22380,\n",
       " '基づく': 18849,\n",
       " '妄想': 19435,\n",
       " 'あるいは': 5709,\n",
       " '高次': 30729,\n",
       " '認知': 28342,\n",
       " 'senses': 4674,\n",
       " 'feelings': 2538,\n",
       " 'emotions': 2397,\n",
       " '情念': 21318,\n",
       " 'passions': 4084,\n",
       " '等': 26277,\n",
       " '対比的': 19923,\n",
       " '用い': 25177,\n",
       " 'られ': 7781,\n",
       " '純粋': 26467,\n",
       " '精神': 26410,\n",
       " '肉体': 27046,\n",
       " '作用': 16128,\n",
       " '考え': 26952,\n",
       " '非常': 30374,\n",
       " '騒がしい': 30671,\n",
       " '場所': 18904,\n",
       " 'ひどく': 7248,\n",
       " '悲しん': 21304,\n",
       " '判断': 17123,\n",
       " '下す': 15122,\n",
       " '困難': 18630,\n",
       " 'なる': 7042,\n",
       " '近年': 29093,\n",
       " '経済': 26582,\n",
       " '実験': 19769,\n",
       " '心理': 21050,\n",
       " '熟慮': 24793,\n",
       " 'かならずしも': 6036,\n",
       " '合理': 18151,\n",
       " '引き起こさ': 20699,\n",
       " '示し': 25854,\n",
       " 'バイアス': 12034,\n",
       " '機能': 23617,\n",
       " '主義': 15458,\n",
       " '学派': 19571,\n",
       " 'ヒト': 12331,\n",
       " '生存': 25134,\n",
       " '結びつい': 26593,\n",
       " '同様': 18210,\n",
       " '進化': 29348,\n",
       " '必ずしも': 21060,\n",
       " '不合理': 15198,\n",
       " '特に': 24880,\n",
       " '祖先': 25890,\n",
       " '時代': 22805,\n",
       " '環境': 25076,\n",
       " '相互': 25573,\n",
       " 'または': 7401,\n",
       " '並列': 15338,\n",
       " '意思': 21356,\n",
       " '決定': 24049,\n",
       " '関わっ': 30000,\n",
       " '示唆': 25859,\n",
       " '二': 15575,\n",
       " '重': 29690,\n",
       " '過程': 29428,\n",
       " '理論': 25064,\n",
       " 'プロセス': 13004,\n",
       " 'スタノヴィッチ': 10651,\n",
       " 'まで': 7414,\n",
       " '提案': 22121,\n",
       " '類似': 30537,\n",
       " '列挙': 17092,\n",
       " 'それら': 6582,\n",
       " '詳細': 28321,\n",
       " '異なる': 25291,\n",
       " '次': 23637,\n",
       " '共通': 16753,\n",
       " '二つ': 15576,\n",
       " 'システム': 10193,\n",
       " 'どの': 6963,\n",
       " 'これら': 6274,\n",
       " '提唱': 22119,\n",
       " '者': 26970,\n",
       " '間': 29983,\n",
       " '合意': 18145,\n",
       " '状況': 24921,\n",
       " '内容': 16805,\n",
       " 'ことなる': 6254,\n",
       " '限界': 30086,\n",
       " '議論': 28606,\n",
       " '二律背反': 15586,\n",
       " '指摘': 21910,\n",
       " 'アロー': 8214,\n",
       " '囚人': 18572,\n",
       " 'ジレンマ': 10571,\n",
       " 'ハイゼンベルク': 11885,\n",
       " '不': 15165,\n",
       " '確定': 25833,\n",
       " '科学': 26014,\n",
       " 'ゲーデル': 9777,\n",
       " '不完全性': 15208,\n",
       " '知識': 25742,\n",
       " '挙げ': 21924,\n",
       " '位相': 16011,\n",
       " '線型': 26738,\n",
       " '函数': 16990,\n",
       " '解析': 28096,\n",
       " 'せん': 6521,\n",
       " 'けいかん': 6190,\n",
       " '多元': 19075,\n",
       " '体': 16041,\n",
       " '実数': 19742,\n",
       " '複素数': 27813,\n",
       " '上': 15055,\n",
       " 'もと': 7539,\n",
       " '演算': 24562,\n",
       " '加法': 17356,\n",
       " '乗法': 15498,\n",
       " '著しい': 27510,\n",
       " '代表': 15866,\n",
       " 'よく': 7749,\n",
       " '知ら': 25711,\n",
       " 'バナッハ': 12099,\n",
       " '単位': 17638,\n",
       " 'かつ': 6029,\n",
       " '結合': 26608,\n",
       " '成す': 21494,\n",
       " '構造': 23541,\n",
       " '閉': 29922,\n",
       " '自然': 27235,\n",
       " '集合': 30226,\n",
       " '生成': 25142,\n",
       " '含む': 18302,\n",
       " '最小': 22996,\n",
       " 'すなわち': 6471,\n",
       " '交わり': 15645,\n",
       " '直線': 25562,\n",
       " '内': 16796,\n",
       " '有界': 23065,\n",
       " '区間': 17544,\n",
       " 'に対して': 7091,\n",
       " 'ストーン': 10732,\n",
       " 'ヴァイアシュトラス': 14761,\n",
       " '用いれ': 25180,\n",
       " '恒等': 21223,\n",
       " '一元': 14886,\n",
       " 'わかる': 7821,\n",
       " 'に対し': 7090,\n",
       " '写像': 16879,\n",
       " 'さらに': 6337,\n",
       " '双': 17805,\n",
       " '定義': 19705,\n",
       " 'もっとも': 7534,\n",
       " 'ノルム': 11856,\n",
       " 'に対する': 7092,\n",
       " '広汎': 20543,\n",
       " '既に': 22640,\n",
       " '構築': 23540,\n",
       " '中でも': 15344,\n",
       " '重要': 29728,\n",
       " 'c': 1725,\n",
       " 'フォンノイマン': 12626,\n",
       " '調和': 28467,\n",
       " 'フレシェ': 12708,\n",
       " '劣': 17371,\n",
       " 'に関する': 7101,\n",
       " '半': 17570,\n",
       " '保証': 16252,\n",
       " '可分': 18043,\n",
       " 'コンパクトハウスドルフ': 9910,\n",
       " '複素': 27812,\n",
       " '全体': 16649,\n",
       " '定める': 19683,\n",
       " '入れ': 16610,\n",
       " 'ただし': 6635,\n",
       " 'コンパクト': 9909,\n",
       " '各': 18106,\n",
       " '内部': 16818,\n",
       " '含ま': 18300,\n",
       " '合併': 18141,\n",
       " '被覆': 27738,\n",
       " '収束': 17857,\n",
       " '入る': 16609,\n",
       " '書か': 22913,\n",
       " '開': 29951,\n",
       " '正則': 23709,\n",
       " '付け': 15817,\n",
       " 'したがって': 6373,\n",
       " '多': 19067,\n",
       " '変数': 19009,\n",
       " '論': 28486,\n",
       " '役': 20860,\n",
       " '果たす': 23320,\n",
       " '凸': 16932,\n",
       " 'local': 3507,\n",
       " 'multiplicative': 3799,\n",
       " 'convex': 2017,\n",
       " 'algebra': 1314,\n",
       " 'lmc': 3505,\n",
       " '族': 22636,\n",
       " '備え': 16423,\n",
       " '完備': 19647,\n",
       " '調べる': 28463,\n",
       " 'でき': 6840,\n",
       " 'アレンス': 8211,\n",
       " 'マイケル': 13458,\n",
       " '一般': 14968,\n",
       " 'よい': 7742,\n",
       " '係数': 16210,\n",
       " '有理': 23061,\n",
       " '多項式': 19106,\n",
       " '商': 18458,\n",
       " '考えよ': 26953,\n",
       " '数': 22408,\n",
       " '元': 16499,\n",
       " '解釈': 28106,\n",
       " 'ローラン': 14700,\n",
       " '展開': 20145,\n",
       " '注意': 24177,\n",
       " 'いま': 5799,\n",
       " '定めれ': 19684,\n",
       " '示せる': 25857,\n",
       " '性質': 21197,\n",
       " 'クラス': 9480,\n",
       " '基礎': 18864,\n",
       " '自動的': 27208,\n",
       " '自動': 27207,\n",
       " 'automatic': 1488,\n",
       " 'continuity': 2009,\n",
       " '未': 23130,\n",
       " '解決': 28097,\n",
       " '問題': 18485,\n",
       " 'ほか': 7347,\n",
       " '要請': 27869,\n",
       " '更': 22907,\n",
       " 'q': 4343,\n",
       " '可逆': 18054,\n",
       " '必要': 21066,\n",
       " '十': 17555,\n",
       " '分': 16992,\n",
       " '条件': 23226,\n",
       " '空': 26125,\n",
       " 'スペクトル': 10768,\n",
       " '任意': 15913,\n",
       " '反転': 17840,\n",
       " '先': 16529,\n",
       " '他方': 15804,\n",
       " '一': 14874,\n",
       " '分野': 17038,\n",
       " 'ちょう': 6721,\n",
       " 'わかい': 7816,\n",
       " 'せき': 6507,\n",
       " '信号': 16268,\n",
       " '波': 24161,\n",
       " '重ね': 29700,\n",
       " '合わせ': 18135,\n",
       " '表現': 27706,\n",
       " '関わる': 30003,\n",
       " 'フーリエ': 12744,\n",
       " '級数': 26475,\n",
       " '変換': 19007,\n",
       " '及び': 17787,\n",
       " '研究': 25787,\n",
       " '19': 583,\n",
       " '世紀': 15300,\n",
       " '20': 691,\n",
       " 'を通じて': 7848,\n",
       " '主題': 15465,\n",
       " '広く': 20524,\n",
       " '応用': 21103,\n",
       " '処理': 16926,\n",
       " '量子力学': 29751,\n",
       " '神経': 25934,\n",
       " '多岐': 19081,\n",
       " 'わたる': 7837,\n",
       " 'harmonic': 2892,\n",
       " '物理': 24869,\n",
       " '固有値': 18664,\n",
       " '来': 23233,\n",
       " '楽器': 23515,\n",
       " '弦': 20727,\n",
       " '振動': 21957,\n",
       " '周波数': 18346,\n",
       " '他': 15799,\n",
       " '整数': 22437,\n",
       " '倍': 16323,\n",
       " 'なっ': 7018,\n",
       " '意図': 21352,\n",
       " '原義': 17742,\n",
       " '超え': 28849,\n",
       " 'ヒルベルト': 12351,\n",
       " '文脈': 22493,\n",
       " '有効': 23043,\n",
       " '調べ': 28462,\n",
       " 'おり': 5947,\n",
       " '結ぶ': 26603,\n",
       " '中盤': 15396,\n",
       " '源': 24511,\n",
       " '発する': 25377,\n",
       " '中心': 15377,\n",
       " 'ハウスドルフ': 11912,\n",
       " '種々': 26078,\n",
       " '可': 18042,\n",
       " '換局': 22143,\n",
       " '所': 21589,\n",
       " 'ポントリャーギン': 13444,\n",
       " '双対': 17808,\n",
       " '主': 15430,\n",
       " '特徴': 24884,\n",
       " '十分': 17559,\n",
       " 'および': 5944,\n",
       " 'もっと': 7533,\n",
       " 'たとえば': 6651,\n",
       " '非': 30364,\n",
       " '換': 22130,\n",
       " 'リー': 14401,\n",
       " '拡張': 21864,\n",
       " '試みる': 28274,\n",
       " 'ユニタリ': 14030,\n",
       " '近しい': 29079,\n",
       " '同値': 18179,\n",
       " '類': 30534,\n",
       " '選び出す': 29535,\n",
       " '分解': 17035,\n",
       " '得': 20969,\n",
       " '作り方': 16107,\n",
       " '有用': 23064,\n",
       " '畳み込み': 25311,\n",
       " 'ごと': 6288,\n",
       " '写す': 16876,\n",
       " '保ち': 16237,\n",
       " '台': 18055,\n",
       " '種': 26077,\n",
       " '導く': 19998,\n",
       " '参照': 17778,\n",
       " '未だ': 23131,\n",
       " 'ここ': 6240,\n",
       " '少なくとも': 20068,\n",
       " 'プランシュレル': 12940,\n",
       " '同等': 18220,\n",
       " '多く': 19072,\n",
       " '特殊': 24893,\n",
       " '無限': 24747,\n",
       " '次元': 23646,\n",
       " '役割': 20866,\n",
       " '被': 27729,\n",
       " '正弦': 23727,\n",
       " '和': 18391,\n",
       " '即ち': 17692,\n",
       " 'ので': 7130,\n",
       " '従来': 20965,\n",
       " '短時間': 25754,\n",
       " 'stfd': 4884,\n",
       " '優れ': 16484,\n",
       " '分解能': 17036,\n",
       " '有する': 23034,\n",
       " 'ものの': 7553,\n",
       " '同時に': 18204,\n",
       " '膨大': 27169,\n",
       " '計算': 28167,\n",
       " '量': 29749,\n",
       " '多大': 19078,\n",
       " '要する': 27855,\n",
       " '普及': 22835,\n",
       " '至っ': 27261,\n",
       " 'なかっ': 6986,\n",
       " '機': 23601,\n",
       " '性能': 21196,\n",
       " '向上': 18283,\n",
       " '実用': 19754,\n",
       " 'アルゴリズム': 8150,\n",
       " '開発': 29969,\n",
       " 'ようやく': 7745,\n",
       " 'つつ': 6777,\n",
       " 'nha': 3886,\n",
       " '窓': 26166,\n",
       " '影響': 20858,\n",
       " '受け': 17949,\n",
       " 'にくい': 7066,\n",
       " '高い': 30694,\n",
       " '比べ': 23896,\n",
       " '10': 37,\n",
       " '万': 15005,\n",
       " '100': 38,\n",
       " '億': 16473,\n",
       " '精度': 26407,\n",
       " '見込める': 27987,\n",
       " '微小': 21015,\n",
       " '変化': 19000,\n",
       " '図形': 18645,\n",
       " '一覧': 14975,\n",
       " '様々': 23544,\n",
       " '分類': 17043,\n",
       " 'まず': 7393,\n",
       " '埋め込み': 18812,\n",
       " 'ユークリッド': 14049,\n",
       " '次に': 23643,\n",
       " '球面': 25045,\n",
       " 'コッホ': 9802,\n",
       " '曲線': 22904,\n",
       " '最後': 23002,\n",
       " 'フラクタル': 12661,\n",
       " '別': 17128,\n",
       " '扱い': 21698,\n",
       " 'dim': 2234,\n",
       " '併記': 16141,\n",
       " '大きく': 19124,\n",
       " '等しい': 26280,\n",
       " '通り': 29244,\n",
       " '0': 0,\n",
       " '広がり': 20522,\n",
       " 'すれ': 6485,\n",
       " 'しか': 6357,\n",
       " '作れ': 16112,\n",
       " '吉田': 18164,\n",
       " '洋一': 24189,\n",
       " 'よし': 7750,\n",
       " 'いち': 5770,\n",
       " '1898': 580,\n",
       " '年': 20452,\n",
       " '7': 1070,\n",
       " '月': 23020,\n",
       " '11': 70,\n",
       " '日': 22647,\n",
       " '1989': 679,\n",
       " '8': 1121,\n",
       " '30': 805,\n",
       " '日本': 22663,\n",
       " '東京': 23253,\n",
       " '生まれ': 25113,\n",
       " '1923': 611,\n",
       " '帝国': 20361,\n",
       " '大学': 19162,\n",
       " '理学部': 25049,\n",
       " '学科': 19576,\n",
       " '卒業': 17595,\n",
       " '第一高等学校': 26266,\n",
       " '助教授': 17387,\n",
       " 'フランス': 12675,\n",
       " '留学': 25259,\n",
       " '経': 26574,\n",
       " '1930': 618,\n",
       " '北海道': 17524,\n",
       " '1949': 637,\n",
       " '1964': 653,\n",
       " '立教大学': 26211,\n",
       " 'のち': 7128,\n",
       " '名誉': 18262,\n",
       " '1965': 654,\n",
       " '1969': 658,\n",
       " '埼玉大学': 18869,\n",
       " '教育': 22382,\n",
       " '足跡': 28881,\n",
       " '残し': 23833,\n",
       " '人物': 15723,\n",
       " '随筆': 30159,\n",
       " '家': 19805,\n",
       " '俳人': 16306,\n",
       " '著名': 27514,\n",
       " '夏彦': 19024,\n",
       " '父': 24825,\n",
       " '赤': 28800,\n",
       " '摂': 22182,\n",
       " '也': 15513,\n",
       " '娘': 19478,\n",
       " '翻訳': 26940,\n",
       " '冬子': 16891,\n",
       " '夫': 19311,\n",
       " '戦前': 21549,\n",
       " '北大': 17515,\n",
       " '創設': 17314,\n",
       " '携わり': 22178,\n",
       " '後に': 20914,\n",
       " '努力': 17392,\n",
       " '一時期': 14935,\n",
       " 'やる': 7617,\n",
       " 'いい': 5721,\n",
       " '言わ': 28144,\n",
       " '書': 22911,\n",
       " '練習': 26773,\n",
       " '指示': 21913,\n",
       " '文': 22455,\n",
       " 'せよ': 6516,\n",
       " 'なさい': 7007,\n",
       " '命令': 18384,\n",
       " '使っ': 16154,\n",
       " '1939': 627,\n",
       " '出版': 16974,\n",
       " '発見': 25411,\n",
       " '岩波': 20208,\n",
       " '新書': 22575,\n",
       " '名': 18234,\n",
       " '有名': 23045,\n",
       " '本': 23156,\n",
       " '読み物': 28427,\n",
       " '人': 15693,\n",
       " '支持': 22241,\n",
       " '読ま': 28412,\n",
       " '全書': 16661,\n",
       " '長く': 29875,\n",
       " '細部': 26520,\n",
       " '気': 23932,\n",
       " '配っ': 29637,\n",
       " '構成': 23538,\n",
       " '後': 20911,\n",
       " '模範': 23565,\n",
       " '微分': 21013,\n",
       " '積分': 26112,\n",
       " '序説': 20557,\n",
       " '培風館': 18842,\n",
       " '丁寧': 14996,\n",
       " '解説': 28104,\n",
       " '理工': 25051,\n",
       " '系': 26428,\n",
       " '版': 24841,\n",
       " '新': 22552,\n",
       " 'シリーズ': 10384,\n",
       " '監修': 25490,\n",
       " '担当': 21827,\n",
       " 'テキスト': 11290,\n",
       " '採用': 22040,\n",
       " 'その他': 6559,\n",
       " '多数': 19085,\n",
       " '著作': 27513,\n",
       " '集': 30215,\n",
       " '白': 25427,\n",
       " '林': 23310,\n",
       " '帖': 20354,\n",
       " '影絵': 20857,\n",
       " '広場': 20536,\n",
       " '人生': 15724,\n",
       " '歳月': 23799,\n",
       " '1952': 641,\n",
       " '第': 26262,\n",
       " '回': 18593,\n",
       " 'エッセイスト': 8691,\n",
       " 'クラブ': 9486,\n",
       " '賞': 28762,\n",
       " '受賞': 17982,\n",
       " '閉体': 29927,\n",
       " 'k': 3285,\n",
       " 'だいす': 6686,\n",
       " 'たい': 6595,\n",
       " '根': 23376,\n",
       " '書ける': 22947,\n",
       " '有理数': 23062,\n",
       " 'ラミナ': 14207,\n",
       " '層': 20155,\n",
       " 'ぞ': 6590,\n",
       " 'く': 6135,\n",
       " 'ラミナー': 14208,\n",
       " '種類': 26083,\n",
       " 'ひとつ': 7241,\n",
       " 'v': 5301,\n",
       " 'a': 1225,\n",
       " 'b': 1506,\n",
       " '差': 20303,\n",
       " '交差': 15654,\n",
       " 'intersect': 3163,\n",
       " 'つ': 6736,\n",
       " '互いに': 15600,\n",
       " 'よば': 7759,\n",
       " '無': 24672,\n",
       " '交叉': 15650,\n",
       " 'cross': 2068,\n",
       " 'free': 2640,\n",
       " 'family': 2522,\n",
       " '有向木': 23049,\n",
       " '時空': 22817,\n",
       " 'じ': 6423,\n",
       " 'くう': 6137,\n",
       " '用語': 25188,\n",
       " '関連': 30022,\n",
       " 'ニュートン': 11769,\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnDo6uFfa-97"
   },
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9T8K1Sba-97"
   },
   "source": [
    "## TF-IDF変換\n",
    "---\n",
    "\n",
    "TF-IDF 変換を行うと、単語の出現回数に、他の文書全体と比較した際の希少性 (レア度) で重みを付けることができます。\n",
    "\n",
    "TF-IDF 変換済みの単語文書行列は、`TfidfVectorizer` で作成できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghxLSFzAa-98"
   },
   "source": [
    "### 簡単な例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piBBAXK-a-98"
   },
   "outputs": [],
   "source": [
    "# token_pattern は、デフォルトだと1文字の単語を除外するので、除外しないように設定する\n",
    "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwkRDYC7ylW0"
   },
   "outputs": [],
   "source": [
    "df[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "Lr3yT8tXa-9-",
    "outputId": "31145b0e-e582-490f-ece8-475c9e22a2bd"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "array([[0.42804604, 0.        , 0.        , 0.        , 0.5628291 ,\n",
       "        0.        , 0.42804604, 0.5628291 ],\n",
       "       [0.37302199, 0.49047908, 0.        , 0.49047908, 0.        ,\n",
       "        0.49047908, 0.37302199, 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スペース区切りの文書をリストで与える\n",
    "X = vectorizer.fit_transform([\n",
    "    \"This is a pen\",\n",
    "    \"I am not a pen\",\n",
    "    \"Hello\"\n",
    "])\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TXPjYVtQa--f",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "clf_lr.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "of0bRS66a-9_",
    "outputId": "c1b5329e-5718-4fe7-b497-9ae9c8889003"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>am</th>\n",
       "      <th>hello</th>\n",
       "      <th>i</th>\n",
       "      <th>is</th>\n",
       "      <th>not</th>\n",
       "      <th>pen</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428046</td>\n",
       "      <td>0.562829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.373022</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.373022</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a        am  hello         i        is       not       pen      this\n",
       "0  0.428046  0.000000    0.0  0.000000  0.562829  0.000000  0.428046  0.562829\n",
       "1  0.373022  0.490479    0.0  0.490479  0.000000  0.490479  0.373022  0.000000\n",
       "2  0.000000  0.000000    1.0  0.000000  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ※これは、演習用に単語文書行列を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
    "pd.DataFrame(X.toarray(), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwkAuD2oa--B"
   },
   "source": [
    "他の文書でも出現している単語については、同じ出現回数でも重みが低くなっていることが分かります。各単語の重みは、`idf_` で見ることができます。確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g0m11vAla--g",
        "colab": {}
      },
      "source": [
        "y_test_pred = clf_lr.predict(X_test)\n",
        "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "ImsppSXDa--C",
    "outputId": "20322fe7-be7c-4783-a5bf-21bf34a13a92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28768207, 1.69314718, 1.69314718, 1.69314718, 1.69314718,\n",
       "       1.69314718, 1.28768207, 1.69314718])"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "7-QiVXs_a--E",
    "outputId": "4c6b46b7-7435-45d8-cc6a-58d218b8d790"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>am</th>\n",
       "      <th>hello</th>\n",
       "      <th>i</th>\n",
       "      <th>is</th>\n",
       "      <th>not</th>\n",
       "      <th>pen</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.287682</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a        am     hello  ...       not       pen      this\n",
       "0  1.287682  1.693147  1.693147  ...  1.693147  1.287682  1.693147\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ※これは、演習用に IDF 値を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
    "pd.DataFrame(np.atleast_2d(vectorizer.idf_), columns=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z35bpbtfa--F"
   },
   "source": [
    "デフォルトでは、各文書のノルムが1になるように正規化されています (norm=\"l2\")。確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g9cOBtQ4a--l",
        "colab": {}
      },
      "source": [
        "clf_svc = LinearSVC()\n",
        "clf_svc.fit(X, df[\"category\"])"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "Z2Gle3k3a--G",
    "outputId": "cf770567-59ce-46b6-c97e-7cea0ca0dfe5"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X.toarray(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PiWBOEJ6a--J"
   },
   "source": [
    "### 日本語データに適用\n",
    "CountVectorizer の場合と同様に、前処理済みの日本語データに適用してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcPEur6xa--J"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X = vectorizer.fit_transform(df[\"text_tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GVEYwyxua--m",
        "colab": {}
      },
      "source": [
        "y_test_pred = clf_svc.predict(X_test)\n",
        "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "yB3krCe_a--L",
    "outputId": "3754c951-488f-4dd0-a514-1840c8a5c2ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exlfUKQYa--M"
   },
   "source": [
    "IDF 値の大きい単語・小さい単語を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "7SYAjaLOa--N",
    "outputId": "e750194a-a48d-4184-95ef-3ff216aea720",
    "scrolled": true
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>リゾーマタ</th>\n",
       "      <td>7.215608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下がら</th>\n",
       "      <td>7.215608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下人</th>\n",
       "      <td>7.215608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下中</th>\n",
       "      <td>7.215608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下ろす</th>\n",
       "      <td>7.215608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>に</th>\n",
       "      <td>1.105250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>で</th>\n",
       "      <td>1.080043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>を</th>\n",
       "      <td>1.072496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>は</th>\n",
       "      <td>1.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>の</th>\n",
       "      <td>1.013072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30875 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            idf\n",
       "リゾーマタ  7.215608\n",
       "下がら    7.215608\n",
       "下人     7.215608\n",
       "下中     7.215608\n",
       "下ろす    7.215608\n",
       "...         ...\n",
       "に      1.105250\n",
       "で      1.080043\n",
       "を      1.072496\n",
       "は      1.014085\n",
       "の      1.013072\n",
       "\n",
       "[30875 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ※これは、演習用に IDF 値を DataFrame に変換して見やすくしてみるためのコードで、覚える必要はありません\n",
    "pd.Series(vectorizer.idf_, index=[ x[0] for x in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]) ]) \\\n",
    "    .to_frame(\"idf\") \\\n",
    "    .sort_values(\"idf\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkVS36Cja--O"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rYChGyna--O"
   },
   "source": [
    "## テキスト分類\n",
    "---\n",
    "定量化したテキスト情報を使うことで、テキストをカテゴリー別に分類してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nhbpiDg2a--n",
        "colab": {}
      },
      "source": [
        "clf_rf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
        "clf_rf.fit(X, df[\"category\"])"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "JVGT1gv4a--P",
    "outputId": "5286b250-d7b8-4a71-df97-510791fea29c"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>細見和之 細見和之（ほそみ　かずゆき、1962年2月27日）は、日本の詩人、京都大学教授、大...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>グライバッハ標準形 計算機科学において、文脈自由言語の全ての生成規則が次のように書けるとき、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>淡中圏 淡中圏（たんなかけん、TANNAKIAN CATEGORY）とは与えられた体\"K\"に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>根岸世雄 根岸 世雄（ねぎし ときお、1929年 - 2005年1月26日）は、日本の数学者...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>CEF CEF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                               text\n",
       "0   philosophy  細見和之 細見和之（ほそみ　かずゆき、1962年2月27日）は、日本の詩人、京都大学教授、大...\n",
       "1  mathematics  グライバッハ標準形 計算機科学において、文脈自由言語の全ての生成規則が次のように書けるとき、...\n",
       "2  mathematics  淡中圏 淡中圏（たんなかけん、TANNAKIAN CATEGORY）とは与えられた体\"K\"に...\n",
       "3  mathematics  根岸世雄 根岸 世雄（ねぎし ときお、1929年 - 2005年1月26日）は、日本の数学者...\n",
       "4  mathematics                                           CEF CEF "
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータ\n",
    "df_test = pd.read_csv(\"dataset/wikipedia-test.txt\", sep=\"\\t\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIAl91qja--Q"
   },
   "source": [
    "### 単語文書行列 (TF-IDF 適用済み) の作成\n",
    "単語文章行列を作成する前に、まずは文章を形態素解析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTx-3037a--Q"
   },
   "outputs": [],
   "source": [
    "mecab = MeCab.Tagger(\"-O wakati\")\n",
    "\n",
    "text_tokenized = []\n",
    "for text in df_test['text']:\n",
    "    text_tokenized.append(mecab.parse(text))\n",
    "    \n",
    "df_test['text_tokenized'] = text_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3v5MoEC4a--U"
   },
   "source": [
    "続いて、単語文章行列を学習データテストデータでそれぞれ生成します。<br>\n",
    "この時、2つの単語文章行列は同じ次元数でなければならないので、`transform`を使用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCvYhqiWa--V"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X = vectorizer.fit_transform(df[\"text_tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGoM-SX2a--W"
   },
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(df_test[\"text_tokenized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S88NkqlQa--Z"
   },
   "source": [
    "### 分類器の適用・比較\n",
    "単語文書行列ができたら、後はこれまでやってきた機械学習と同様です。\n",
    "\n",
    "いくつかの分類器で、性能を比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXtCFjkja--a"
   },
   "outputs": [],
   "source": [
    "# Accuracy, Precision/Recall/F-score/Support, Confusion Matrix を表示\n",
    "def show_evaluation_metrics(y_true, y_pred):\n",
    "    print(\"Accuracy:\")\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fT-t_hBma--b"
   },
   "source": [
    "### ロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSc1ShwPa--p",
        "colab": {}
      },
      "source": [
        "y_test_pred = clf_rf.predict(X_test)\n",
        "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "cTmFq6lma--d",
    "outputId": "79eebb13-98b6-4303-c4ba-9a6486be1983"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(n_jobs=-1)\n",
    "clf_lr.fit(X, df[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MInsT37Ha--f"
   },
   "source": [
    "推定結果は predict で得ることができます (他の分類器でも同様)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "TXPjYVtQa--f",
    "outputId": "ae1ed7c2-c620-4fdb-b817-67a4edef310b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['philosophy', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'philosophy',\n",
       "       'philosophy', 'philosophy', 'philosophy', 'philosophy',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'philosophy',\n",
       "       'mathematics', 'mathematics', 'philosophy', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'philosophy', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'philosophy',\n",
       "       'philosophy', 'mathematics', 'philosophy', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'philosophy', 'philosophy', 'mathematics', 'philosophy',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'philosophy', 'mathematics', 'mathematics', 'philosophy',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'philosophy',\n",
       "       'philosophy', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'philosophy', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "g0m11vAla--g",
    "outputId": "adc89332-8402-40d2-f7c4-8c656ca28e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.89\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " mathematics       0.89      0.96      0.92        67\n",
      "  philosophy       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.89      0.86      0.87       100\n",
      "weighted avg       0.89      0.89      0.89       100\n",
      "\n",
      "Confusion matrix:\n",
      "[[64  3]\n",
      " [ 8 25]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf_lr.predict(X_test)\n",
    "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgstWu1sa--j"
   },
   "source": [
    "### SVM (線形カーネル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "g9cOBtQ4a--l",
    "outputId": "0d230670-71ad-4ec2-d3d2-e236902c9ac0"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = LinearSVC()\n",
    "clf_svc.fit(X, df[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hEgXmXvha--w",
        "colab": {}
      },
      "source": [
        "joblib.dump(clf_rf, \"wikipedia_category_classifier.pkl.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "GVEYwyxua--m",
    "outputId": "6ff4d49b-bd88-4fb5-cdb4-ed0b5192d2a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.92\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " mathematics       0.93      0.96      0.94        67\n",
      "  philosophy       0.90      0.85      0.88        33\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.92      0.90      0.91       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n",
      "Confusion matrix:\n",
      "[[64  3]\n",
      " [ 5 28]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf_svc.predict(X_test)\n",
    "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5fYOekxa--n"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "nhbpiDg2a--n",
    "outputId": "b6d4d96f-7d35-4b76-90c8-10401acfa225"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "clf_rf.fit(X, df[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tDXcsBD8a--1",
        "colab": {}
      },
      "source": [
        "clf_rf_restored = joblib.load(\"wikipedia_category_classifier.pkl.gz\")\n",
        "clf_rf_restored"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "zSc1ShwPa--p",
    "outputId": "e11088d5-2090-4ad9-d00c-3f071e5c54d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.89\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " mathematics       0.89      0.96      0.92        67\n",
      "  philosophy       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.89      0.86      0.87       100\n",
      "weighted avg       0.89      0.89      0.89       100\n",
      "\n",
      "Confusion matrix:\n",
      "[[64  3]\n",
      " [ 8 25]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf_rf.predict(X_test)\n",
    "show_evaluation_metrics(df_test[\"category\"], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IepwcsMa--r"
   },
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oxDCnVRa--r"
   },
   "source": [
    "## 【演習1】\n",
    "上記いずれかのアルゴリズムのパラメータを変更して、分類精度を高めてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bCd0XTqa--s"
   },
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GoAMg4Rka--u"
   },
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CB2NQkE2a--w"
   },
   "source": [
    "### モデルの保存\n",
    "`pickle` でも保存できますが、`joblib` を使い、ファイル名末尾に `.gz`, `.bz2` 等を指定すると、自動的に圧縮してくれます。読み込み時も同様、自動的に解凍して読み込んでくれます。\n",
    "\n",
    "言語処理ではモデルが大容量になることが多いため、モデルの圧縮は重要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "hEgXmXvha--w",
    "outputId": "f3943e96-c2e6-4645-d053-bdfe72d6fef1"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "['wikipedia_category_classifier.pkl.gz']"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_rf, \"wikipedia_category_classifier.pkl.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kh4d5bGPa--1"
   },
   "source": [
    "### モデル読み込みテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mgq0KeTwa--2",
        "colab": {}
      },
      "source": [
        "clf_rf_restored.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
>>>>>>> 4d1546359a2d9a30c05a14bc2b2e5f2deb0dde8b
    },
    "colab_type": "code",
    "id": "tDXcsBD8a--1",
    "outputId": "2ab0b82d-8fc8-40e5-e9a3-fd3a31d419e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf_restored = joblib.load(\"wikipedia_category_classifier.pkl.gz\")\n",
    "clf_rf_restored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6V5U9o3ha--2"
   },
   "source": [
    "読み込んだモデルは、上記ですでに学習済みなので、`predict`で予測が行えます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "mgq0KeTwa--2",
    "outputId": "a0bafcc1-0b4e-44a4-a2d6-f51ef4b2695c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['philosophy', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'philosophy',\n",
       "       'philosophy', 'mathematics', 'philosophy', 'philosophy',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'philosophy',\n",
       "       'mathematics', 'philosophy', 'philosophy', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'philosophy', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'philosophy',\n",
       "       'philosophy', 'mathematics', 'philosophy', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'philosophy',\n",
       "       'philosophy', 'philosophy', 'mathematics', 'philosophy',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'philosophy', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'philosophy',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'philosophy',\n",
       "       'philosophy', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'philosophy', 'mathematics', 'mathematics',\n",
       "       'philosophy', 'mathematics', 'mathematics', 'mathematics',\n",
       "       'mathematics', 'mathematics', 'mathematics', 'mathematics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf_restored.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJjIJ-Fqa--3"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5arU5BH_a--4"
   },
   "source": [
    "## 【演習2】\n",
    "演習1で構築したモデルをjoblibを使って保存してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugLnx-9La--4"
   },
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnaU7hXDrQNn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TYMmznRYa-9Q",
    "0zHt5kiTa-9d",
    "fUP0dONFa-9y",
    "ghxLSFzAa-98",
    "PiWBOEJ6a--J",
    "JIAl91qja--Q",
    "S88NkqlQa--Z",
    "fT-t_hBma--b",
    "zgstWu1sa--j",
    "G5fYOekxa--n",
    "CB2NQkE2a--w",
    "kh4d5bGPa--1"
   ],
   "include_colab_link": true,
   "name": "myMecab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
